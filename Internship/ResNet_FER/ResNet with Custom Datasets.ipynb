{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom datasets file 위치 : '/home/sldev1/Project/hyeongeun_test/data'   \n",
    "먼저 할 것은, tar를 시각적으로 어케보는지 확인해보자.\n",
    "###### 완료\n",
    "-----\n",
    "라벨링 어떻게 되어있는지 데이터 확인하자.   \n",
    "10/26일 할일 annotation 어케 되어있는지 확인하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tar Data Visualization (22.10.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tarfile.open('/home/sldev1/Project/hyeongeun_test/data/train_set.tar', 'r') as tar_file:\n",
    "    print(tar_file.getnames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = tarfile.open('/home/sldev1/Project/hyeongeun_test/data/train_set.tar', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d506f9a1d4b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m Image(tar\n\u001b[0m\u001b[1;32m      4\u001b[0m      )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "type(tar)\n",
    "list(tar)\n",
    "Image(tar\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import tarfile\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "IMG_EXTENSIONS = ['.png', '.jpg', '.jpeg']\n",
    "\n",
    "\n",
    "def natural_key(string_):\n",
    "    \"\"\"See http://www.codinghorror.com/blog/archives/001018.html\"\"\"\n",
    "    return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_.lower())]\n",
    "\n",
    "\n",
    "def _extract_tar_info(tarfile):\n",
    "    class_to_idx = {}\n",
    "    files = []\n",
    "    targets = []\n",
    "    for ti in tarfile.getmembers():\n",
    "        if not ti.isfile():\n",
    "            continue\n",
    "        dirname, basename = os.path.split(ti.path)\n",
    "        target = os.path.basename(dirname)\n",
    "        class_to_idx[target] = None\n",
    "        ext = os.path.splitext(basename)[1]\n",
    "        if ext.lower() in IMG_EXTENSIONS:\n",
    "            files.append(ti)\n",
    "            targets.append(target)\n",
    "    for idx, c in enumerate(sorted(class_to_idx.keys(), key=natural_key)):\n",
    "        class_to_idx[c] = idx\n",
    "    tarinfo_and_targets = zip(files, [class_to_idx[t] for t in targets])\n",
    "    tarinfo_and_targets = sorted(tarinfo_and_targets, key=lambda k: natural_key(k[0].path))\n",
    "    return tarinfo_and_targets\n",
    "\n",
    "\n",
    "class ImageFolderTar(data.Dataset):\n",
    "\n",
    "    def __init__(self, root, transform=None):\n",
    "\n",
    "        assert os.path.isfile(root)\n",
    "        self.root = root\n",
    "        with tarfile.open(root) as tf:  # cannot keep this open across processes, reopen later\n",
    "            self.imgs = _extract_tar_info(tf)\n",
    "        self.tarfile = None  # lazy init in __getitem__\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.tarfile is None:\n",
    "            self.tarfile = tarfile.open(self.root)\n",
    "        tarinfo, target = self.imgs[index]\n",
    "        iob = self.tarfile.extractfile(tarinfo)\n",
    "        img = Image.open(iob).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = ImageFolderTar(root='/home/sldev1/Project/hyeongeun_test/data/train_set.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as tr\n",
    "\n",
    "transf = tr.Compose(tr.RandomCrop(32, padding=4))\n",
    "test2 = ImageFolderTar(root='/home/sldev1/Project/hyeongeun_test/data/train_set.tar', trainsform=transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test2[0].tarinfo\n",
    "img, target = test1[5]\n",
    "img.show()\n",
    "\n",
    "\n",
    "#test1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Annotaion Check (2022.10.26)\n",
    "#### 1. npy파일 타입의 이점(insight 용, 결론 : better than csv, txt)   \n",
    "https://towardsdatascience.com/what-is-npy-files-and-why-you-should-use-them-603373c78883   \n",
    "   \n",
    "#### 2. 상준 선임님께 img+npy 합쳐서 못보냐고 물어봤는데, 답은 여기는 없다고 하심.   \n",
    "고로, Data Annotation Check는 npy 염탐하는 부분에서 마무리 짓겠음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### npy file 염탐하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.137627\n"
     ]
    }
   ],
   "source": [
    "data_array = np.load('/home/sldev1/Project/hyeongeun_test/data/FER/train_set/annotations/100000_aro.npy')\n",
    "print(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "data_array = np.load('/home/sldev1/Project/hyeongeun_test/data/FER/train_set/annotations/100000_exp.npy')\n",
    "print(data_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 위에 정수 값 별 의미\n",
    "0 : Neutral   \n",
    "1 : Happiness   \n",
    "2 : Sadness   \n",
    "3 : Suprise   \n",
    "4 : Fear   \n",
    "5 : Disgust   \n",
    "6 : Anger   \n",
    "7 : Content   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3.66446602 108.67054545  -2.27262136 132.00727273   0.45669903\n",
      " 153.72509091   9.07961165 176.288       22.04116505 195.08363636\n",
      "  40.73320388 210.27490909  66.85203883 220.70109091  92.18796117\n",
      " 228.24581818 116.28427184 228.94836364 136.38990291 222.77818182\n",
      " 151.68932039 206.95563636 166.72776699 190.4        176.52504854\n",
      " 171.88945455 181.61398058 152.17745455 186.05048544 130.97890909\n",
      " 188.24699029 112.90618182 186.77902913  93.968       20.88854369\n",
      "  73.07490909  37.38407767  64.45090909  54.68427184  60.11345455\n",
      "  73.92        60.79563636  90.61126214  69.17527273 126.37514563\n",
      "  66.80290909 140.79378641  57.46618182 156.27805825  52.96581818\n",
      " 171.81669903  54.19781818 183.4407767   63.53454545 110.41242718\n",
      "  86.352      113.63106796 102.24581818 117.31728155 117.42690909\n",
      " 120.69902913 133.25963636  98.37514563 147.20872727 108.17242718\n",
      " 148.94981818 117.26291262 150.79272727 125.38563107 147.392\n",
      " 132.51883495 142.61672727  42.73398058  93.58109091  53.82524272\n",
      "  85.12        67.80893204  84.38690909  80.65087379  93.78472727\n",
      "  68.02640777  97.33818182  53.54252427  98.49890909 130.27883495\n",
      "  89.87490909 141.77242718  79.25527273 155.65825243  77.69745455\n",
      " 164.61825243  85.40509091 157.6807767   90.64872727 144.38213592\n",
      "  91.46327273  73.74601942 176.48145455  92.38368932 172.02181818\n",
      " 107.29165049 167.552      115.08815534 169.24218182 122.41708738\n",
      " 165.60727273 132.84504854 167.45018182 143.45786408 169.15054545\n",
      " 134.03029126 180.24872727 124.5592233  184.69818182 116.68660194\n",
      " 186.91781818 108.58563107 187.32509091  92.67728155 185.73672727\n",
      "  82.03184466 176.80727273 107.82446602 176.07418182 115.63184466\n",
      " 176.49163636 123.14563107 174.48581818 137.44466019 171.85890909\n",
      " 123.31961165 173.49818182 115.77320388 175.59563636 107.90058252\n",
      " 175.79927273]\n"
     ]
    }
   ],
   "source": [
    "data_array = np.load('/home/sldev1/Project/hyeongeun_test/data/FER/train_set/annotations/100000_lnd.npy')\n",
    "print(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784476\n"
     ]
    }
   ],
   "source": [
    "data_array = np.load('/home/sldev1/Project/hyeongeun_test/data/FER/train_set/annotations/100000_val.npy')\n",
    "print(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3999\n",
      "15996\n"
     ]
    }
   ],
   "source": [
    "print(len(img_list))\n",
    "print(len(annot_list)) #img : annot = 1 : 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/sldev1/Project/hyeongeun_test/data/FER/val_set/images/0.jpg', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/images/1.jpg', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/images/10.jpg', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/images/100.jpg', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/images/1001.jpg', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/images/1002.jpg', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/images/1003.jpg', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/images/1007.jpg', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/images/1008.jpg', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/images/1009.jpg']\n",
      "['/home/sldev1/Project/hyeongeun_test/data/FER/val_set/annotations/0_aro.npy', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/annotations/0_exp.npy', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/annotations/0_lnd.npy', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/annotations/0_val.npy', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/annotations/1001_aro.npy', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/annotations/1001_exp.npy', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/annotations/1001_lnd.npy', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/annotations/1001_val.npy', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/annotations/1002_aro.npy', '/home/sldev1/Project/hyeongeun_test/data/FER/val_set/annotations/1002_exp.npy']\n"
     ]
    }
   ],
   "source": [
    "print(img_list[:10])\n",
    "print(annot_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15996\n"
     ]
    }
   ],
   "source": [
    "print(3999*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## npy Custom Data training with pytorch (2022.10.26)\n",
    "#### 1. baseline code\n",
    "https://freshrimpsushi.github.io/posts/how-to-create-and-use-custom-data-set-from-numpy-arrays-in-pytorch/   \n",
    "위에꺼 일단 보류.   \n",
    "밥먹고나서 데이터불러오기_커스터마이징 참고해서 이 파일 위에 tar visual부분이랑 결합해서 해보자.   \n",
    "일단 1개 npy부터 해보자.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import tarfile\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "IMG_EXTENSIONS = ['.png', '.jpg', '.jpeg']\n",
    "\n",
    "\n",
    "def natural_key(string_):\n",
    "    \"\"\"See http://www.codinghorror.com/blog/archives/001018.html\"\"\"\n",
    "    return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_.lower())]\n",
    "\n",
    "\n",
    "def _extract_tar_info(tarfile):\n",
    "    class_to_idx = {}\n",
    "    files = []\n",
    "    targets = []\n",
    "    for ti in tarfile.getmembers():\n",
    "        if not ti.isfile():\n",
    "            continue\n",
    "        dirname, basename = os.path.split(ti.path)\n",
    "        target = os.path.basename(dirname)\n",
    "        class_to_idx[target] = None\n",
    "        ext = os.path.splitext(basename)[1]\n",
    "        if ext.lower() in IMG_EXTENSIONS:\n",
    "            files.append(ti)\n",
    "            targets.append(target)\n",
    "    for idx, c in enumerate(sorted(class_to_idx.keys(), key=natural_key)):\n",
    "        class_to_idx[c] = idx\n",
    "    tarinfo_and_targets = zip(files, [class_to_idx[t] for t in targets])\n",
    "    tarinfo_and_targets = sorted(tarinfo_and_targets, key=lambda k: natural_key(k[0].path))\n",
    "    return tarinfo_and_targets\n",
    "\n",
    "\n",
    "class ImageFolderTar(data.Dataset):\n",
    "\n",
    "    def __init__(self, root, transform=None):\n",
    "\n",
    "        assert os.path.isfile(root)\n",
    "        self.root = root\n",
    "        with tarfile.open(root) as tf:  # cannot keep this open across processes, reopen later\n",
    "            self.imgs = _extract_tar_info(tf)\n",
    "        self.tarfile = None  # lazy init in __getitem__\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.tarfile is None:\n",
    "            self.tarfile = tarfile.open(self.root)\n",
    "        tarinfo, target = self.imgs[index]\n",
    "        iob = self.tarfile.extractfile(tarinfo)\n",
    "        img = Image.open(iob).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = ImageFolderTar(root='/home/sldev1/Project/hyeongeun_test/data/train_set.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = tr.Compose([tr.RandomCrop(32, padding=4), \n",
    "                              tr.ToTensor(),\n",
    "                              tr.Normalize])\n",
    "transform_test = tr.Compose([tr.ToTensor()])\n",
    "\n",
    "\n",
    "train_dataset = ImageFolderTar(root='/home/sldev1/Project/hyeongeun_test/data/train_set.', transform=transform_train)\n",
    "test_dataset = ImageFolderTar(root='/home/sldev1/Project/hyeongeun_test/data/val_set.tar', transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "287651\n"
     ]
    }
   ],
   "source": [
    "img, target = train_dataset[3]\n",
    "print(img.shape)\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2248"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-1-5849c200a3a0>\", line 54, in __getitem__\n    img = Image.open(iob).convert('RGB')\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 915, in convert\n    self.load()\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\", line 274, in load\n    raise_oserror(err_code)\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\", line 67, in raise_oserror\n    raise OSError(message + \" when reading image file\")\nOSError: broken data stream when reading image file\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-ef49e3308b55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-1-5849c200a3a0>\", line 54, in __getitem__\n    img = Image.open(iob).convert('RGB')\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 915, in convert\n    self.load()\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\", line 274, in load\n    raise_oserror(err_code)\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\", line 67, in raise_oserror\n    raise OSError(message + \" when reading image file\")\nOSError: broken data stream when reading image file\n"
     ]
    }
   ],
   "source": [
    "#num_workers=2이상으로 설정하니까 Error나네?\n",
    "#num_workers 설정 안하면 Error안남.\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 32, 32])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "customdata를 data load까지 전처리 완료!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 학습시켜볼게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from resnet import ResNet18, ResNet34, ResNet50, ResNet101, ResNet152\n",
    "import os\n",
    "import torchvision.models as models\n",
    "\n",
    "''' random seed fixed'''\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Learning Rate Scheduler\n",
    "def lr_scheduler(optimizer, epoch):\n",
    "    lr = learning_rate\n",
    "    if epoch >= 50:\n",
    "        lr /= 10\n",
    "    if epoch >= 100:\n",
    "        lr /= 10\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "# Xavier\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = ResNet50()\n",
    "# ResNet18, ResNet34, ResNet50, ResNet101, ResNet152 중에 택일하여 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model.apply(init_weights)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "num_epoch = 150\n",
    "model_name = 'model.pth'\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "train_loss = 0\n",
    "valid_loss = 0\n",
    "correct = 0\n",
    "total_cnt = 0\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "에러남 ㅠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== 1 epoch of 150 ======\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "Caught UnidentifiedImageError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-1-5849c200a3a0>\", line 54, in __getitem__\n    img = Image.open(iob).convert('RGB')\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 3031, in open\n    \"cannot identify image file %r\" % (filename if filename else fp)\nPIL.UnidentifiedImageError: cannot identify image file <ExFileObject name='/home/sldev1/Project/hyeongeun_test/data/train_set.tar'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-6f8d7b48778a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtotal_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Train Phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m#  input and target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: Caught UnidentifiedImageError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-1-5849c200a3a0>\", line 54, in __getitem__\n    img = Image.open(iob).convert('RGB')\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 3031, in open\n    \"cannot identify image file %r\" % (filename if filename else fp)\nPIL.UnidentifiedImageError: cannot identify image file <ExFileObject name='/home/sldev1/Project/hyeongeun_test/data/train_set.tar'>\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for epoch in range(num_epoch):\n",
    "    print(f\"====== { epoch+1} epoch of { num_epoch } ======\")\n",
    "    model.train()\n",
    "    lr_scheduler(optimizer, epoch)\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    total_cnt = 0\n",
    "    # Train Phase\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        #  input and target\n",
    "        batch[0], batch[1] = batch[0].to(device), batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(batch[0])\n",
    "        loss = loss_fn(logits, batch[1])\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predict = logits.max(1)\n",
    "        \n",
    "        total_cnt += batch[1].size(0)\n",
    "        correct +=  predict.eq(batch[1]).sum().item()\n",
    "        \n",
    "        if step % 100 == 0 and step != 0:\n",
    "            print(f\"\\n====== { step } Step of { len(train_loader) } ======\")\n",
    "            print(f\"Train Acc : { correct / total_cnt }\")\n",
    "            print(f\"Train Loss : { loss.item() / batch[1].size(0) }\")\n",
    "            \n",
    "    correct = 0\n",
    "    total_cnt = 0\n",
    "    \n",
    "# Test Phase\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for step, batch in enumerate(test_loader):\n",
    "            # input and target\n",
    "            batch[0], batch[1] = batch[0].to(device), batch[1].to(device)\n",
    "            total_cnt += batch[1].size(0)\n",
    "            logits = model(batch[0])\n",
    "            valid_loss += loss_fn(logits, batch[1])\n",
    "            _, predict = logits.max(1)\n",
    "            correct += predict.eq(batch[1]).sum().item()\n",
    "        valid_acc = correct / total_cnt\n",
    "        print(f\"\\nValid Acc : { valid_acc }\")    \n",
    "        print(f\"Valid Loss : { valid_loss / total_cnt }\")\n",
    "\n",
    "        if(valid_acc > best_acc):\n",
    "            best_acc = valid_acc\n",
    "            torch.save(model, model_name)\n",
    "            print(\"Model Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "상준 선임님 왈:\n",
    "1. 파싱 먼저하고\n",
    "2. function 만들어 준다.\n",
    "'''\n",
    "\n",
    "###난이도 너무 높아졌는데 ???????????????/ 집간다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTIONS = [{\"Neutral\"   : \"0\",\n",
    "            \"Happiness\" : \"1\",\n",
    "            \"Sadness\"   : \"2\", \n",
    "            \"Suprise\"   : \"3\", \n",
    "            \"Fear\"      : \"4\", \n",
    "            \"Disgust\"   : \"5\", \n",
    "            \"Anger\"     : \"6\",\n",
    "            \"Content\"   : \"7\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
