{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG model 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in_channel = 들어가는 이미지의 채널 수\n",
    "- out_channel = 나오는 이미지의 채널 수 (사실 상 사용하고자하는 필터의 개수 라고 봐도됨)   \n",
    "https://gaussian37.github.io/dl-pytorch-conv2d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9754, 0.2203],\n",
       "          [0.0147, 0.3246]],\n",
       "\n",
       "         [[0.7968, 0.8747],\n",
       "          [0.4509, 0.3188]]],\n",
       "\n",
       "\n",
       "        [[[0.2569, 0.9425],\n",
       "          [0.4605, 0.6515]],\n",
       "\n",
       "         [[0.8878, 0.1607],\n",
       "          [0.1273, 0.4537]]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(4,4)\n",
    "a = a.view(2,2,2,2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#torch.Size([32, 3, 224, 224]) = img\n",
    "input = torch.ones(1, 1, 3, 3)\n",
    "filter = torch.ones(1, 1, 3, 3)\n",
    "filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = Variable(input, requires_grad=True)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = Variable(filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[9.]]]], grad_fn=<ThnnConv2DBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = F.conv2d(input, filter)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ThnnConv2DBackward0 object at 0x7f81eadf9668>\n"
     ]
    }
   ],
   "source": [
    "out.backward()\n",
    "print(out.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "print(input.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG + tensorboard + torchinfo + Epoch당 걸리는 시간\n",
    "11.10(목)\n",
    "- 코드 리뷰\n",
    "    - 하나부터 열까지 다 이해함을 목표로 진행.\n",
    "1. [궁금한 점 (언더바 차이)](#궁금한-점(언더바-차이))\n",
    "2. [궁금한 점 (init_weight)](#궁금한-점-(init_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as tr\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "from VGG import VGG11, VGG13, VGG16, VGG19\n",
    "\n",
    "import os\n",
    "from skimage import io, transform\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "path = \"/home/sldev1/Project/hyeongeun_test/data/FER\"\n",
    "\n",
    "\n",
    "''' random seed fixed'''\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = VGG16()\n",
    "learning_rate =0.001\n",
    "# VGG11, VGG13, VGG16, VGG19 중에 택일하여 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'init_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8917640cd737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     print(param)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'init_weights' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_uniform(m.weight)\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     print(param)\n",
    "\n",
    "model.apply(init_weights)\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "\n",
    "\n",
    "# model.parameters()\n",
    "# print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 궁금한 점(언더바 차이)\n",
    "1. kaiming_uniform_, kaiming_uniform에서 언더바 있고 없고 차이점 궁금   \n",
    "2. Vgg에서 Linear 다음도 ReLU인데, 그럼 kaiming_uniform 써야되는거 아닌지??   \n",
    "    - 가져온 코드라 왜 이렇게 짰는지 궁금해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Learning Rate Scheduler\n",
    "def lr_scheduler(optimizer, epoch):\n",
    "    lr = learning_rate\n",
    "    if epoch == 50:\n",
    "        lr /= 2\n",
    "    if epoch == 100:\n",
    "        lr /= 2\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr \n",
    "\n",
    "# Xavier, 가중치 초기화 부분\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_uniform(m.weight)\n",
    "    # if isinstance(m, nn.ReLU):\n",
    "    #     torch.nn.init.kaiming_uniform_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi, i'm main\n"
     ]
    }
   ],
   "source": [
    "def img_load(img_path):\n",
    "\n",
    "    jpg = glob.glob(img_path+'*.jpg')\n",
    "    sort_jpg = sorted(jpg, key=lambda s: int(re.findall(r'\\d+', s)[1]))\n",
    "    #print(\"img_load def is play\")\n",
    "    return sort_jpg\n",
    "\n",
    "\n",
    "def label_load(label_path):\n",
    "    #enumerate #파이썬내장함수.. 강민규사원님은 이걸로 쓰셨는데 느리더래\n",
    "    label = glob.glob(label_path+'*exp.npy')\n",
    "    sort_label = sorted(label,key=lambda s: int(re.findall(r'\\d+', s)[1]))\n",
    "    #print(\"label_load def is play\")\n",
    "    return sort_label\n",
    "\n",
    "class MyFERDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_path_base, label_path_base, train=None, transform=None):\n",
    "        super(MyFERDataset, self).__init__()\n",
    "        \n",
    "        if train == True:\n",
    "            self.img_path = img_path_base+'/train_set/images/'\n",
    "            self.label_path = label_path_base+'/train_set/annotations/'\n",
    "        else:\n",
    "            self.img_path = img_path_base+'/val_set/images/'\n",
    "            self.label_path = label_path_base+'/val_set/annotations/'\n",
    "\n",
    "        self.img = img_load(self.img_path)\n",
    "        self.label = label_load(self.label_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_read = io.imread(self.img[idx]) \n",
    "        label_read = np.load(self.label[idx])\n",
    "        label_read = label_read.astype(np.int64)\n",
    "        label_tr = torch.from_numpy(label_read)\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            img_tr = self.transform(img_read)\n",
    "        \n",
    "        \n",
    "        return img_tr, label_tr\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    if __name__ == \"__main__\":\n",
    "        print('hi, i\\'m main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = tr.Compose([tr.ToTensor(),\n",
    "                              tr.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "transform_test = tr.Compose([tr.ToTensor()])\n",
    "\n",
    "\n",
    "train_dataset = MyFERDataset(img_path_base = path,\n",
    "                              label_path_base = path,\n",
    "                              train=True,\n",
    "                              transform=transform_train)\n",
    "test_dataset = MyFERDataset(img_path_base = path,\n",
    "                              label_path_base = path,\n",
    "                              train=False,\n",
    "                              transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287651"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.size()\n",
    "#print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 1, 1, 1, 0, 3, 0, 0, 6, 0, 1, 1, 1, 1, 0, 1, 0, 2, 3, 6, 1, 1,\n",
      "        0, 0, 2, 1, 5, 1, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = VGG16()\n",
    "# VGG11, VGG13, VGG16, VGG19 중에 택일하여 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 궁금한 점 (init_weight)\n",
    "1. apply 함수 시퀀스 궁금. (상준선임, 민규사원님께 물어볼 것)   \n",
    "    - 참고 자료 : [apply docs](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)   \n",
    "    - 참고 자료 : [apply source docs](https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.apply)\n",
    "2. 얼마만큼 재귀적으로 불러오는지 어떻게 아는지 궁금.\n",
    "    - apply시 한번만 초기화하는지?\n",
    "    - 그걸 어떻게 아는지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model.apply(init_weights) # 재귀적으로 모델 전체 가중치를 초기화\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epoch = 200\n",
    "model_name = 'VGG_FER.pth'\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_loss = 0\n",
    "valid_loss = 0\n",
    "correct = 0\n",
    "total_cnt = 0\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기서 걸리는 시간 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== 1 epoch of 200 ======\n",
      "\n",
      "====== 1000 Step of 8990 ======\n",
      "Train Acc : 0.49063436563436563\n",
      "Train Loss : 0.032309286296367645\n",
      "\n",
      "====== 2000 Step of 8990 ======\n",
      "Train Acc : 0.5499437781109445\n",
      "Train Loss : 0.05138865113258362\n",
      "\n",
      "====== 3000 Step of 8990 ======\n",
      "Train Acc : 0.5767556647784072\n",
      "Train Loss : 0.030065201222896576\n",
      "\n",
      "====== 4000 Step of 8990 ======\n",
      "Train Acc : 0.5919145213696576\n",
      "Train Loss : 0.03900831937789917\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() #시작 시간 저장\n",
    "# Train\n",
    "writer = SummaryWriter()\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    if epoch == 1:\n",
    "        start = time.time() #시작 시간 저장\n",
    "    if epoch == 2:\n",
    "        epoch_time_for_1 = time.time()-start\n",
    "        timer = epoch_time_for_1 * num_epoch\n",
    "        print(\"학습에 총 걸리는 시간 :\", timer)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f\"====== { epoch+1} epoch of { num_epoch } ======\")\n",
    "    model.train()\n",
    "    lr_scheduler(optimizer, epoch)\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    total_cnt = 0\n",
    "    \n",
    "    \n",
    "    #writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    #writer.add_scalar('Loss/valid', np.random.random(), n_iter)\n",
    "    #writer.add_scalar('Accuracy/train', valid_loss, epoch)\n",
    "    #writer.add_scalar('Accuracy/valid', np.random.random(), n_iter)\n",
    "    \n",
    "    # Train Phase\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        #  input and target\n",
    "        batch[0], batch[1] = batch[0].to(device), batch[1].to(device) # batch[0]은 이미지 / batch[1]은 label\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(batch[0])\n",
    "        loss = loss_fn(logits, batch[1])\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predict = logits.max(1)\n",
    "        \n",
    "        total_cnt += batch[1].size(0)\n",
    "        correct +=  predict.eq(batch[1]).sum().item()\n",
    "        \n",
    "        \n",
    "        if step % 1000 == 0 and step != 0:\n",
    "            print(f\"\\n====== { step } Step of { len(train_loader) } ======\")\n",
    "            print(f\"Train Acc : { correct / total_cnt }\")\n",
    "            print(f\"Train Loss : { loss.item() / batch[1].size(0) }\")\n",
    "\n",
    "    \n",
    "    train_acc_visual = (correct / total_cnt) * 100\n",
    "    train_loss_visual = loss.item() / batch[1].size(0)\n",
    "    writer.add_scalar('acc/train', train_acc_visual, epoch)\n",
    "    writer.add_scalar('loss/train', train_loss_visual, epoch)\n",
    "\n",
    "        \n",
    "            \n",
    "    correct = 0\n",
    "    total_cnt = 0\n",
    "    \n",
    "# Test Phase\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for step, batch in enumerate(test_loader):\n",
    "            # input and target\n",
    "            batch[0], batch[1] = batch[0].to(device), batch[1].to(device)\n",
    "            total_cnt += batch[1].size(0)\n",
    "            logits = model(batch[0])\n",
    "            valid_loss += loss_fn(logits, batch[1])\n",
    "            _, predict = logits.max(1)\n",
    "            correct += predict.eq(batch[1]).sum().item()\n",
    "        valid_acc = correct / total_cnt\n",
    "        print(f\"\\nValid Acc : { valid_acc }\")    \n",
    "        print(f\"Valid Loss : { valid_loss / total_cnt }\")\n",
    "        valid_acc_visual = valid_acc * 100\n",
    "        valid_loss_visual = valid_loss / total_cnt\n",
    "        writer.add_scalar('acc/valid', valid_acc_visual, epoch)\n",
    "        writer.add_scalar('loss/valid', valid_loss_visual, epoch)\n",
    "\n",
    "        if(valid_acc > best_acc):\n",
    "            best_acc = valid_acc\n",
    "            #torch.save(model, model_name)\n",
    "            torch.save(model.state_dict(), model_name)\n",
    "            print(\"Model Saved!\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.7.0 at http://localhost:6007/ (Press CTRL+C to quit)\n",
      "W1109 14:00:37.641661 140120865257216 security_validator.py:46] In 3.0, this warning will become an error:\n",
      "X-Content-Type-Options is required to be \"nosniff\"\n",
      "W1109 14:00:37.704443 140120865257216 security_validator.py:46] In 3.0, this warning will become an error:\n",
      "X-Content-Type-Options is required to be \"nosniff\"\n",
      "W1109 14:00:37.704560 140120865257216 security_validator.py:46] In 3.0, this warning will become an error:\n",
      "Requires default-src for Content-Security-Policy\n",
      "W1109 14:00:37.720740 140120865257216 security_validator.py:46] In 3.0, this warning will become an error:\n",
      "X-Content-Type-Options is required to be \"nosniff\"\n",
      "W1109 14:00:38.251987 140120865257216 application.py:556] path /data/plugin/whatif/data/plugins_listing not found, sending 404\n",
      "W1109 14:00:38.306895 140119054964480 application.py:556] path /data/plugin/whatif/data/plugins_listing not found, sending 404\n",
      "W1109 14:00:38.344264 140119054964480 application.py:556] path /data/plugin/whatif/data/plugins_listing not found, sending 404\n",
      "W1109 14:00:38.346859 140119054964480 application.py:556] path /data/plugin/whatif/data/plugins_listing not found, sending 404\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "----\n",
    "## 참고자료\n",
    "- 논문 구현\n",
    "    - [링크](https://cryptosalamander.tistory.com/158)\n",
    "- tensorboard\n",
    "    - [링크](https://gaussian37.github.io/dl-pytorch-observe/#tensorboard%EB%A5%BC-%ED%86%B5%ED%95%9C-%ED%95%99%EC%8A%B5-%ED%98%84%ED%99%A9-%ED%99%95%EC%9D%B8-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
