{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as tr\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "transf = tr.Compose(\n",
    "    [tr.ToTensor(),\n",
    "     tr.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data/', train=False, download=True, transform=transf)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 *5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.213\n",
      "[1,  4000] loss: 1.870\n",
      "[1,  6000] loss: 1.705\n",
      "[1,  8000] loss: 1.587\n",
      "[1, 10000] loss: 1.528\n",
      "[1, 12000] loss: 1.482\n",
      "[2,  2000] loss: 1.416\n",
      "[2,  4000] loss: 1.387\n",
      "[2,  6000] loss: 1.374\n",
      "[2,  8000] loss: 1.350\n",
      "[2, 10000] loss: 1.322\n",
      "[2, 12000] loss: 1.303\n",
      "[3,  2000] loss: 1.241\n",
      "[3,  4000] loss: 1.248\n",
      "[3,  6000] loss: 1.240\n",
      "[3,  8000] loss: 1.218\n",
      "[3, 10000] loss: 1.216\n",
      "[3, 12000] loss: 1.205\n",
      "[4,  2000] loss: 1.114\n",
      "[4,  4000] loss: 1.151\n",
      "[4,  6000] loss: 1.153\n",
      "[4,  8000] loss: 1.134\n",
      "[4, 10000] loss: 1.141\n",
      "[4, 12000] loss: 1.133\n",
      "[5,  2000] loss: 1.057\n",
      "[5,  4000] loss: 1.061\n",
      "[5,  6000] loss: 1.076\n",
      "[5,  8000] loss: 1.076\n",
      "[5, 10000] loss: 1.065\n",
      "[5, 12000] loss: 1.094\n",
      "[6,  2000] loss: 0.981\n",
      "[6,  4000] loss: 1.019\n",
      "[6,  6000] loss: 1.009\n",
      "[6,  8000] loss: 1.021\n",
      "[6, 10000] loss: 1.039\n",
      "[6, 12000] loss: 1.024\n",
      "[7,  2000] loss: 0.940\n",
      "[7,  4000] loss: 0.943\n",
      "[7,  6000] loss: 0.963\n",
      "[7,  8000] loss: 0.985\n",
      "[7, 10000] loss: 1.016\n",
      "[7, 12000] loss: 0.977\n",
      "[8,  2000] loss: 0.890\n",
      "[8,  4000] loss: 0.901\n",
      "[8,  6000] loss: 0.916\n",
      "[8,  8000] loss: 0.957\n",
      "[8, 10000] loss: 0.956\n",
      "[8, 12000] loss: 0.966\n",
      "[9,  2000] loss: 0.840\n",
      "[9,  4000] loss: 0.883\n",
      "[9,  6000] loss: 0.893\n",
      "[9,  8000] loss: 0.901\n",
      "[9, 10000] loss: 0.915\n",
      "[9, 12000] loss: 0.948\n",
      "[10,  2000] loss: 0.825\n",
      "[10,  4000] loss: 0.827\n",
      "[10,  6000] loss: 0.863\n",
      "[10,  8000] loss: 0.870\n",
      "[10, 10000] loss: 0.895\n",
      "[10, 12000] loss: 0.910\n",
      "[11,  2000] loss: 0.778\n",
      "[11,  4000] loss: 0.828\n",
      "[11,  6000] loss: 0.815\n",
      "[11,  8000] loss: 0.868\n",
      "[11, 10000] loss: 0.874\n",
      "[11, 12000] loss: 0.899\n",
      "[12,  2000] loss: 0.751\n",
      "[12,  4000] loss: 0.797\n",
      "[12,  6000] loss: 0.816\n",
      "[12,  8000] loss: 0.837\n",
      "[12, 10000] loss: 0.844\n",
      "[12, 12000] loss: 0.851\n",
      "[13,  2000] loss: 0.723\n",
      "[13,  4000] loss: 0.763\n",
      "[13,  6000] loss: 0.795\n",
      "[13,  8000] loss: 0.809\n",
      "[13, 10000] loss: 0.826\n",
      "[13, 12000] loss: 0.849\n",
      "[14,  2000] loss: 0.719\n",
      "[14,  4000] loss: 0.739\n",
      "[14,  6000] loss: 0.787\n",
      "[14,  8000] loss: 0.795\n",
      "[14, 10000] loss: 0.806\n",
      "[14, 12000] loss: 0.811\n",
      "[15,  2000] loss: 0.683\n",
      "[15,  4000] loss: 0.747\n",
      "[15,  6000] loss: 0.743\n",
      "[15,  8000] loss: 0.768\n",
      "[15, 10000] loss: 0.789\n",
      "[15, 12000] loss: 0.820\n",
      "[16,  2000] loss: 0.671\n",
      "[16,  4000] loss: 0.715\n",
      "[16,  6000] loss: 0.753\n",
      "[16,  8000] loss: 0.758\n",
      "[16, 10000] loss: 0.785\n",
      "[16, 12000] loss: 0.785\n",
      "[17,  2000] loss: 0.683\n",
      "[17,  4000] loss: 0.701\n",
      "[17,  6000] loss: 0.699\n",
      "[17,  8000] loss: 0.743\n",
      "[17, 10000] loss: 0.787\n",
      "[17, 12000] loss: 0.797\n",
      "[18,  2000] loss: 0.677\n",
      "[18,  4000] loss: 0.703\n",
      "[18,  6000] loss: 0.718\n",
      "[18,  8000] loss: 0.738\n",
      "[18, 10000] loss: 0.754\n",
      "[18, 12000] loss: 0.747\n",
      "[19,  2000] loss: 0.655\n",
      "[19,  4000] loss: 0.680\n",
      "[19,  6000] loss: 0.716\n",
      "[19,  8000] loss: 0.725\n",
      "[19, 10000] loss: 0.748\n",
      "[19, 12000] loss: 0.766\n",
      "[20,  2000] loss: 0.642\n",
      "[20,  4000] loss: 0.671\n",
      "[20,  6000] loss: 0.695\n",
      "[20,  8000] loss: 0.719\n",
      "[20, 10000] loss: 0.723\n",
      "[20, 12000] loss: 0.768\n",
      "[21,  2000] loss: 0.642\n",
      "[21,  4000] loss: 0.655\n",
      "[21,  6000] loss: 0.682\n",
      "[21,  8000] loss: 0.689\n",
      "[21, 10000] loss: 0.734\n",
      "[21, 12000] loss: 0.741\n",
      "[22,  2000] loss: 0.614\n",
      "[22,  4000] loss: 0.664\n",
      "[22,  6000] loss: 0.667\n",
      "[22,  8000] loss: 0.680\n",
      "[22, 10000] loss: 0.723\n",
      "[22, 12000] loss: 0.732\n",
      "[23,  2000] loss: 0.593\n",
      "[23,  4000] loss: 0.649\n",
      "[23,  6000] loss: 0.669\n",
      "[23,  8000] loss: 0.697\n",
      "[23, 10000] loss: 0.723\n",
      "[23, 12000] loss: 0.706\n",
      "[24,  2000] loss: 0.590\n",
      "[24,  4000] loss: 0.645\n",
      "[24,  6000] loss: 0.667\n",
      "[24,  8000] loss: 0.685\n",
      "[24, 10000] loss: 0.714\n",
      "[24, 12000] loss: 0.702\n",
      "[25,  2000] loss: 0.596\n",
      "[25,  4000] loss: 0.642\n",
      "[25,  6000] loss: 0.695\n",
      "[25,  8000] loss: 0.686\n",
      "[25, 10000] loss: 0.677\n",
      "[25, 12000] loss: 0.721\n",
      "[26,  2000] loss: 0.587\n",
      "[26,  4000] loss: 0.616\n",
      "[26,  6000] loss: 0.662\n",
      "[26,  8000] loss: 0.684\n",
      "[26, 10000] loss: 0.689\n",
      "[26, 12000] loss: 0.711\n",
      "[27,  2000] loss: 0.587\n",
      "[27,  4000] loss: 0.632\n",
      "[27,  6000] loss: 0.676\n",
      "[27,  8000] loss: 0.675\n",
      "[27, 10000] loss: 0.722\n",
      "[27, 12000] loss: 0.736\n",
      "[28,  2000] loss: 0.588\n",
      "[28,  4000] loss: 0.612\n",
      "[28,  6000] loss: 0.665\n",
      "[28,  8000] loss: 0.660\n",
      "[28, 10000] loss: 0.708\n",
      "[28, 12000] loss: 0.709\n",
      "[29,  2000] loss: 0.597\n",
      "[29,  4000] loss: 0.610\n",
      "[29,  6000] loss: 0.649\n",
      "[29,  8000] loss: 0.678\n",
      "[29, 10000] loss: 0.680\n",
      "[29, 12000] loss: 0.712\n",
      "[30,  2000] loss: 0.570\n",
      "[30,  4000] loss: 0.617\n",
      "[30,  6000] loss: 0.652\n",
      "[30,  8000] loss: 0.689\n",
      "[30, 10000] loss: 0.695\n",
      "[30, 12000] loss: 0.747\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):   # 데이터셋을 수차례 반복합니다.\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # [inputs, labels]의 목록인 data로부터 입력을 받은 후;\n",
    "        inputs, labels = data\n",
    "\n",
    "        # 변화도(Gradient) 매개변수를 0으로 만들고\n",
    "        # 옵티마이저 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파 + 역전파 + 최적화를 한 후\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 통계를 출력합니다.\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  plane truck deer  deer \n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 58 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# 학습 중이 아니므로, 출력에 대한 변화도를 계산할 필요가 없습니다\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # 신경망에 이미지를 통과시켜 출력을 계산합니다\n",
    "        outputs = net(images)\n",
    "        # 가장 높은 값(energy)를 갖는 분류(class)를 정답으로 선택하겠습니다\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 78.4 %\n",
      "Accuracy for class: car   is 69.8 %\n",
      "Accuracy for class: bird  is 48.5 %\n",
      "Accuracy for class: cat   is 37.1 %\n",
      "Accuracy for class: deer  is 50.3 %\n",
      "Accuracy for class: dog   is 52.4 %\n",
      "Accuracy for class: frog  is 64.9 %\n",
      "Accuracy for class: horse is 58.2 %\n",
      "Accuracy for class: ship  is 64.2 %\n",
      "Accuracy for class: truck is 61.5 %\n"
     ]
    }
   ],
   "source": [
    "# 각 분류(class)에 대한 예측값 계산을 위해 준비\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# 변화도는 여전히 필요하지 않습니다\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # 각 분류별로 올바른 예측 수를 모읍니다\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# 각 분류별 정확도(accuracy)를 출력합니다\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet Code 쳐보면서 궁금한거 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "\n",
    "# model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "from torch import optim\n",
    "\n",
    "# dataset and transformation\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as tr\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "\n",
    "# display images\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# utils\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# FER Summary\n",
    "from skimage import io, transform\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import re\n",
    "import PIL\n",
    "\n",
    "# random seed fixed\n",
    "''' random seed fixed'''\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "path = \"/home/sldev1/Project/hyeongeun_test/data/FER\"\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi, i'm main\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "\n",
    "\n",
    "def img_load(img_path):\n",
    "\n",
    "    jpg = glob.glob(img_path+'*.jpg')\n",
    "    sort_jpg = sorted(jpg, key=lambda s: int(re.findall(r'\\d+', s)[1]))\n",
    "    #print(\"img_load def is play\")\n",
    "    return sort_jpg\n",
    "\n",
    "\n",
    "def label_load(label_path):\n",
    "    #enumerate #파이썬내장함수.. 강민규사원님은 이걸로 쓰셨는데 느리더래\n",
    "    label = glob.glob(label_path+'*exp.npy')\n",
    "    sort_label = sorted(label,key=lambda s: int(re.findall(r'\\d+', s)[1]))\n",
    "    #print(\"label_load def is play\")\n",
    "    return sort_label\n",
    "    \n",
    "    \n",
    "    \n",
    "class MyFERDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_path_base, label_path_base, train=None, transform=None):\n",
    "        super(MyFERDataset, self).__init__()\n",
    "        \n",
    "        if train == True:\n",
    "            self.img_path = img_path_base+'/train_set/images/'\n",
    "            self.label_path = label_path_base+'/train_set/annotations/'\n",
    "        else:\n",
    "            self.img_path = img_path_base+'/val_set/images/'\n",
    "            self.label_path = label_path_base+'/val_set/annotations/'\n",
    "\n",
    "        self.img = img_load(self.img_path)\n",
    "        self.label = label_load(self.label_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_read = io.imread(self.img[idx]) \n",
    "        label_read = np.load(self.label[idx])\n",
    "        label_read = label_read.astype(np.int64)\n",
    "        label_tr = torch.from_numpy(label_read)\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            img_tr = self.transform(img_read)\n",
    "        \n",
    "        \n",
    "        return img_tr, label_tr\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    if __name__ == \"__main__\":\n",
    "        print('hi, i\\'m main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depthwise Saparable Convolution\n",
    "class Depthwise(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.depthwise = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 3, stride=stride, padding=1, groups=in_channels, bias=False),\n",
    "            # ==> nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "            # ==> kernel size = 3 이란 말은, 3x3을 의미함.\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU6()\n",
    "        )\n",
    "        \n",
    "        self.pointwise = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU6()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Depthwise(\n",
       "  (depthwise): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU6()\n",
       "  )\n",
       "  (pointwise): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU6()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Depthwise(32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Conv2d\n",
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, **kwargs),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd + backward 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.tensor(data = [2.0, 3.0], requires_grad=True)\n",
    "y = x**2\n",
    "z = 2*y + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8., 17.], grad_fn=<SubBackward0>)\n",
      "tensor([ 8., 17.], grad_fn=<AbsBackward0>)\n",
      "tensor(25., grad_fn=<SumBackward0>)\n",
      "loss :  tensor(25., grad_fn=<SumBackward0>)\n",
      "loss_2 :  tensor([ 8., 17.], grad_fn=<AbsBackward0>)\n",
      "tensor([ 8., 12.]) None None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor(data = [2.0, 3.0], requires_grad=True)\n",
    "y = x**2\n",
    "z = 2*y + 3\n",
    "\n",
    "target = torch.tensor([3.0, 4.0])\n",
    "loss = torch.sum(torch.abs(z-target))\n",
    "print(z-target)\n",
    "print(torch.abs(z-target))\n",
    "print(loss)\n",
    "loss_2 = torch.abs(z-target)\n",
    "loss.backward()\n",
    "print('loss : ',loss)\n",
    "\n",
    "print('loss_2 : ', loss_2)\n",
    "\n",
    "print(x.grad, y.grad, z.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "for a in range(10):\n",
    "    print(a)\n",
    "\n",
    "print(\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
