{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tqdm 이쁘게쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6513c41f57486fba41e71233fe10c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ab1bc0338d433992e95bafeb6fdeb4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f5a5d9833746ca8c9248492464844f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da220594213140518b5a536991d99bb7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e95080f94a409b8b8b1a48f36dfa46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72be4fcfb68c40b2babaa86c4216fc87"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-70eb44d49af1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1st loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2nd loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm, trange\n",
    "from time import sleep\n",
    " \n",
    "for i in trange(10, desc='1st loop'):\n",
    "    for j in tqdm(range(100), desc='2nd loop'):\n",
    "        sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as tr\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "transf = tr.Compose(\n",
    "    [tr.ToTensor(),\n",
    "     tr.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data/', train=False, download=True, transform=transf)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 *5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.213\n",
      "[1,  4000] loss: 1.870\n",
      "[1,  6000] loss: 1.705\n",
      "[1,  8000] loss: 1.587\n",
      "[1, 10000] loss: 1.528\n",
      "[1, 12000] loss: 1.482\n",
      "[2,  2000] loss: 1.416\n",
      "[2,  4000] loss: 1.387\n",
      "[2,  6000] loss: 1.374\n",
      "[2,  8000] loss: 1.350\n",
      "[2, 10000] loss: 1.322\n",
      "[2, 12000] loss: 1.303\n",
      "[3,  2000] loss: 1.241\n",
      "[3,  4000] loss: 1.248\n",
      "[3,  6000] loss: 1.240\n",
      "[3,  8000] loss: 1.218\n",
      "[3, 10000] loss: 1.216\n",
      "[3, 12000] loss: 1.205\n",
      "[4,  2000] loss: 1.114\n",
      "[4,  4000] loss: 1.151\n",
      "[4,  6000] loss: 1.153\n",
      "[4,  8000] loss: 1.134\n",
      "[4, 10000] loss: 1.141\n",
      "[4, 12000] loss: 1.133\n",
      "[5,  2000] loss: 1.057\n",
      "[5,  4000] loss: 1.061\n",
      "[5,  6000] loss: 1.076\n",
      "[5,  8000] loss: 1.076\n",
      "[5, 10000] loss: 1.065\n",
      "[5, 12000] loss: 1.094\n",
      "[6,  2000] loss: 0.981\n",
      "[6,  4000] loss: 1.019\n",
      "[6,  6000] loss: 1.009\n",
      "[6,  8000] loss: 1.021\n",
      "[6, 10000] loss: 1.039\n",
      "[6, 12000] loss: 1.024\n",
      "[7,  2000] loss: 0.940\n",
      "[7,  4000] loss: 0.943\n",
      "[7,  6000] loss: 0.963\n",
      "[7,  8000] loss: 0.985\n",
      "[7, 10000] loss: 1.016\n",
      "[7, 12000] loss: 0.977\n",
      "[8,  2000] loss: 0.890\n",
      "[8,  4000] loss: 0.901\n",
      "[8,  6000] loss: 0.916\n",
      "[8,  8000] loss: 0.957\n",
      "[8, 10000] loss: 0.956\n",
      "[8, 12000] loss: 0.966\n",
      "[9,  2000] loss: 0.840\n",
      "[9,  4000] loss: 0.883\n",
      "[9,  6000] loss: 0.893\n",
      "[9,  8000] loss: 0.901\n",
      "[9, 10000] loss: 0.915\n",
      "[9, 12000] loss: 0.948\n",
      "[10,  2000] loss: 0.825\n",
      "[10,  4000] loss: 0.827\n",
      "[10,  6000] loss: 0.863\n",
      "[10,  8000] loss: 0.870\n",
      "[10, 10000] loss: 0.895\n",
      "[10, 12000] loss: 0.910\n",
      "[11,  2000] loss: 0.778\n",
      "[11,  4000] loss: 0.828\n",
      "[11,  6000] loss: 0.815\n",
      "[11,  8000] loss: 0.868\n",
      "[11, 10000] loss: 0.874\n",
      "[11, 12000] loss: 0.899\n",
      "[12,  2000] loss: 0.751\n",
      "[12,  4000] loss: 0.797\n",
      "[12,  6000] loss: 0.816\n",
      "[12,  8000] loss: 0.837\n",
      "[12, 10000] loss: 0.844\n",
      "[12, 12000] loss: 0.851\n",
      "[13,  2000] loss: 0.723\n",
      "[13,  4000] loss: 0.763\n",
      "[13,  6000] loss: 0.795\n",
      "[13,  8000] loss: 0.809\n",
      "[13, 10000] loss: 0.826\n",
      "[13, 12000] loss: 0.849\n",
      "[14,  2000] loss: 0.719\n",
      "[14,  4000] loss: 0.739\n",
      "[14,  6000] loss: 0.787\n",
      "[14,  8000] loss: 0.795\n",
      "[14, 10000] loss: 0.806\n",
      "[14, 12000] loss: 0.811\n",
      "[15,  2000] loss: 0.683\n",
      "[15,  4000] loss: 0.747\n",
      "[15,  6000] loss: 0.743\n",
      "[15,  8000] loss: 0.768\n",
      "[15, 10000] loss: 0.789\n",
      "[15, 12000] loss: 0.820\n",
      "[16,  2000] loss: 0.671\n",
      "[16,  4000] loss: 0.715\n",
      "[16,  6000] loss: 0.753\n",
      "[16,  8000] loss: 0.758\n",
      "[16, 10000] loss: 0.785\n",
      "[16, 12000] loss: 0.785\n",
      "[17,  2000] loss: 0.683\n",
      "[17,  4000] loss: 0.701\n",
      "[17,  6000] loss: 0.699\n",
      "[17,  8000] loss: 0.743\n",
      "[17, 10000] loss: 0.787\n",
      "[17, 12000] loss: 0.797\n",
      "[18,  2000] loss: 0.677\n",
      "[18,  4000] loss: 0.703\n",
      "[18,  6000] loss: 0.718\n",
      "[18,  8000] loss: 0.738\n",
      "[18, 10000] loss: 0.754\n",
      "[18, 12000] loss: 0.747\n",
      "[19,  2000] loss: 0.655\n",
      "[19,  4000] loss: 0.680\n",
      "[19,  6000] loss: 0.716\n",
      "[19,  8000] loss: 0.725\n",
      "[19, 10000] loss: 0.748\n",
      "[19, 12000] loss: 0.766\n",
      "[20,  2000] loss: 0.642\n",
      "[20,  4000] loss: 0.671\n",
      "[20,  6000] loss: 0.695\n",
      "[20,  8000] loss: 0.719\n",
      "[20, 10000] loss: 0.723\n",
      "[20, 12000] loss: 0.768\n",
      "[21,  2000] loss: 0.642\n",
      "[21,  4000] loss: 0.655\n",
      "[21,  6000] loss: 0.682\n",
      "[21,  8000] loss: 0.689\n",
      "[21, 10000] loss: 0.734\n",
      "[21, 12000] loss: 0.741\n",
      "[22,  2000] loss: 0.614\n",
      "[22,  4000] loss: 0.664\n",
      "[22,  6000] loss: 0.667\n",
      "[22,  8000] loss: 0.680\n",
      "[22, 10000] loss: 0.723\n",
      "[22, 12000] loss: 0.732\n",
      "[23,  2000] loss: 0.593\n",
      "[23,  4000] loss: 0.649\n",
      "[23,  6000] loss: 0.669\n",
      "[23,  8000] loss: 0.697\n",
      "[23, 10000] loss: 0.723\n",
      "[23, 12000] loss: 0.706\n",
      "[24,  2000] loss: 0.590\n",
      "[24,  4000] loss: 0.645\n",
      "[24,  6000] loss: 0.667\n",
      "[24,  8000] loss: 0.685\n",
      "[24, 10000] loss: 0.714\n",
      "[24, 12000] loss: 0.702\n",
      "[25,  2000] loss: 0.596\n",
      "[25,  4000] loss: 0.642\n",
      "[25,  6000] loss: 0.695\n",
      "[25,  8000] loss: 0.686\n",
      "[25, 10000] loss: 0.677\n",
      "[25, 12000] loss: 0.721\n",
      "[26,  2000] loss: 0.587\n",
      "[26,  4000] loss: 0.616\n",
      "[26,  6000] loss: 0.662\n",
      "[26,  8000] loss: 0.684\n",
      "[26, 10000] loss: 0.689\n",
      "[26, 12000] loss: 0.711\n",
      "[27,  2000] loss: 0.587\n",
      "[27,  4000] loss: 0.632\n",
      "[27,  6000] loss: 0.676\n",
      "[27,  8000] loss: 0.675\n",
      "[27, 10000] loss: 0.722\n",
      "[27, 12000] loss: 0.736\n",
      "[28,  2000] loss: 0.588\n",
      "[28,  4000] loss: 0.612\n",
      "[28,  6000] loss: 0.665\n",
      "[28,  8000] loss: 0.660\n",
      "[28, 10000] loss: 0.708\n",
      "[28, 12000] loss: 0.709\n",
      "[29,  2000] loss: 0.597\n",
      "[29,  4000] loss: 0.610\n",
      "[29,  6000] loss: 0.649\n",
      "[29,  8000] loss: 0.678\n",
      "[29, 10000] loss: 0.680\n",
      "[29, 12000] loss: 0.712\n",
      "[30,  2000] loss: 0.570\n",
      "[30,  4000] loss: 0.617\n",
      "[30,  6000] loss: 0.652\n",
      "[30,  8000] loss: 0.689\n",
      "[30, 10000] loss: 0.695\n",
      "[30, 12000] loss: 0.747\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):   # 데이터셋을 수차례 반복합니다.\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # [inputs, labels]의 목록인 data로부터 입력을 받은 후;\n",
    "        inputs, labels = data\n",
    "\n",
    "        # 변화도(Gradient) 매개변수를 0으로 만들고\n",
    "        # 옵티마이저 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파 + 역전파 + 최적화를 한 후\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 통계를 출력합니다.\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  plane truck deer  deer \n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 58 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# 학습 중이 아니므로, 출력에 대한 변화도를 계산할 필요가 없습니다\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # 신경망에 이미지를 통과시켜 출력을 계산합니다\n",
    "        outputs = net(images)\n",
    "        # 가장 높은 값(energy)를 갖는 분류(class)를 정답으로 선택하겠습니다\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 78.4 %\n",
      "Accuracy for class: car   is 69.8 %\n",
      "Accuracy for class: bird  is 48.5 %\n",
      "Accuracy for class: cat   is 37.1 %\n",
      "Accuracy for class: deer  is 50.3 %\n",
      "Accuracy for class: dog   is 52.4 %\n",
      "Accuracy for class: frog  is 64.9 %\n",
      "Accuracy for class: horse is 58.2 %\n",
      "Accuracy for class: ship  is 64.2 %\n",
      "Accuracy for class: truck is 61.5 %\n"
     ]
    }
   ],
   "source": [
    "# 각 분류(class)에 대한 예측값 계산을 위해 준비\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# 변화도는 여전히 필요하지 않습니다\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # 각 분류별로 올바른 예측 수를 모읍니다\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# 각 분류별 정확도(accuracy)를 출력합니다\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet Code 쳐보면서 궁금한거 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "\n",
    "# model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "from torch import optim\n",
    "\n",
    "# dataset and transformation\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as tr\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "\n",
    "# display images\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# utils\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# FER Summary\n",
    "from skimage import io, transform\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import re\n",
    "import PIL\n",
    "\n",
    "# random seed fixed\n",
    "''' random seed fixed'''\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "path = \"/home/sldev1/Project/hyeongeun_test/data/FER\"\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi, i'm main\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "\n",
    "\n",
    "def img_load(img_path):\n",
    "\n",
    "    jpg = glob.glob(img_path+'*.jpg')\n",
    "    sort_jpg = sorted(jpg, key=lambda s: int(re.findall(r'\\d+', s)[1]))\n",
    "    #print(\"img_load def is play\")\n",
    "    return sort_jpg\n",
    "\n",
    "\n",
    "def label_load(label_path):\n",
    "    #enumerate #파이썬내장함수.. 강민규사원님은 이걸로 쓰셨는데 느리더래\n",
    "    label = glob.glob(label_path+'*exp.npy')\n",
    "    sort_label = sorted(label,key=lambda s: int(re.findall(r'\\d+', s)[1]))\n",
    "    #print(\"label_load def is play\")\n",
    "    return sort_label\n",
    "    \n",
    "    \n",
    "    \n",
    "class MyFERDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_path_base, label_path_base, train=None, transform=None):\n",
    "        super(MyFERDataset, self).__init__()\n",
    "        \n",
    "        if train == True:\n",
    "            self.img_path = img_path_base+'/train_set/images/'\n",
    "            self.label_path = label_path_base+'/train_set/annotations/'\n",
    "        else:\n",
    "            self.img_path = img_path_base+'/val_set/images/'\n",
    "            self.label_path = label_path_base+'/val_set/annotations/'\n",
    "\n",
    "        self.img = img_load(self.img_path)\n",
    "        self.label = label_load(self.label_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_read = io.imread(self.img[idx]) \n",
    "        label_read = np.load(self.label[idx])\n",
    "        label_read = label_read.astype(np.int64)\n",
    "        label_tr = torch.from_numpy(label_read)\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            img_tr = self.transform(img_read)\n",
    "        \n",
    "        \n",
    "        return img_tr, label_tr\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    if __name__ == \"__main__\":\n",
    "        print('hi, i\\'m main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depthwise Saparable Convolution\n",
    "class Depthwise(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.depthwise = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 3, stride=stride, padding=1, groups=in_channels, bias=False),\n",
    "            # ==> nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "            # ==> kernel size = 3 이란 말은, 3x3을 의미함.\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU6()\n",
    "        )\n",
    "        \n",
    "        self.pointwise = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU6()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Depthwise(\n",
       "  (depthwise): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU6()\n",
       "  )\n",
       "  (pointwise): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU6()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Depthwise(32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Conv2d\n",
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, **kwargs),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd + backward 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.tensor(data = [2.0, 3.0], requires_grad=True)\n",
    "y = x**2\n",
    "z = 2*y + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8., 17.], grad_fn=<SubBackward0>)\n",
      "tensor([ 8., 17.], grad_fn=<AbsBackward0>)\n",
      "tensor(25., grad_fn=<SumBackward0>)\n",
      "loss :  tensor(25., grad_fn=<SumBackward0>)\n",
      "loss_2 :  tensor([ 8., 17.], grad_fn=<AbsBackward0>)\n",
      "tensor([ 8., 12.]) None None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor(data = [2.0, 3.0], requires_grad=True)\n",
    "y = x**2\n",
    "z = 2*y + 3\n",
    "\n",
    "target = torch.tensor([3.0, 4.0])\n",
    "loss = torch.sum(torch.abs(z-target))\n",
    "print(z-target)\n",
    "print(torch.abs(z-target))\n",
    "print(loss)\n",
    "loss_2 = torch.abs(z-target)\n",
    "loss.backward()\n",
    "print('loss : ',loss)\n",
    "\n",
    "print('loss_2 : ', loss_2)\n",
    "\n",
    "print(x.grad, y.grad, z.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "for a in range(10):\n",
    "    print(a)\n",
    "\n",
    "print(\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11/24 목 loss 계산하는 법 탐구 중에 CrossEntropy를 알아야 될 것 같아서 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_prediction :\n",
      " tensor([[2.0000, 0.1000],\n",
      "        [0.0000, 1.0000]])\n",
      "*********************************\n",
      "torch.Size([2, 2])\n",
      "torch.FloatTensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction = torch.Tensor([[2, 0.1], [0, 1]])\n",
    "# 실제 사용에서는 softmax에 의해 각 행의 합이 1이 될 것이다.\n",
    "print(\"test_prediction :\\n\", test_prediction)\n",
    "print(\"*********************************\")\n",
    "print(test_prediction.shape) # size\n",
    "print(test_prediction.type())\n",
    "type(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true_1 = torch.Tensor([1, 0]).long() # 1은 true값이 1번째(클래스)라는 것을 의미\n",
    "test_true_2 = torch.Tensor([0, 1]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.1000],\n",
      "        [0.0000, 1.0000]])\n",
      "*********************************\n",
      "tensor([1, 0])\n",
      "*********************************\n",
      "tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "print(test_prediction)\n",
    "print(\"*********************************\")\n",
    "print(test_true_1)\n",
    "print(\"*********************************\")\n",
    "print(test_true_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6763)\n",
      "tensor(0.2263)\n",
      "1.9026483297348022\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(test_prediction, test_true_1))\n",
    "print(loss_func(test_prediction, test_true_2))\n",
    "print((loss_func(test_prediction, test_true_2)+ loss_func(test_prediction, test_true_1)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,1,1],\n",
    "                  [1,1,1]])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from resnet import ResNet18, ResNet34, ResNet50, ResNet101, ResNet152\n",
    "import os\n",
    "import torchvision.models as models\n",
    "from skimage import io, transform\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch\n",
    "import re\n",
    "import PIL\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as tr\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "######################################################### random seed fixed\n",
    "import random\n",
    "\n",
    "path = \"/home/sldev1/Project/hyeongeun_test/data/FER\"\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "\n",
    "########################################################## Simple Learning Rate Scheduler\n",
    "def lr_scheduler(optimizer, epoch):\n",
    "    lr = learning_rate\n",
    "    if epoch == 50:\n",
    "        lr /= 2\n",
    "    if epoch == 100:\n",
    "        lr /= 2\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "# Xavier\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "        \n",
    "        \n",
    "######################################################### 경로 따오고 sort 하는 함수\n",
    "import glob\n",
    "\n",
    "def img_load(img_path):\n",
    "\n",
    "    jpg = glob.glob(img_path+'*.jpg')\n",
    "    sort_jpg = sorted(jpg, key=lambda s: int(re.findall(r'\\d+', s)[1]))\n",
    "    #print(\"img_load def is play\")\n",
    "    return sort_jpg\n",
    "\n",
    "\n",
    "def label_load(label_path):\n",
    "    #enumerate #파이썬내장함수.. 강민규사원님은 이걸로 쓰셨는데 느리더래\n",
    "    label = glob.glob(label_path+'*exp.npy')\n",
    "    sort_label = sorted(label,key=lambda s: int(re.findall(r'\\d+', s)[1]))\n",
    "    #print(\"label_load def is play\")\n",
    "    return sort_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi, i'm main\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "\n",
    "\n",
    "def img_load(img_path):\n",
    "\n",
    "    jpg = glob.glob(img_path+'*.jpg')\n",
    "    sort_jpg = sorted(jpg, key=lambda s: int(re.findall(r'\\d+', s)[1]))\n",
    "    #print(\"img_load def is play\")\n",
    "    return sort_jpg\n",
    "\n",
    "\n",
    "def label_load(label_path):\n",
    "    #enumerate #파이썬내장함수.. 강민규사원님은 이걸로 쓰셨는데 느리더래\n",
    "    label = glob.glob(label_path+'*exp.npy')\n",
    "    sort_label = sorted(label,key=lambda s: int(re.findall(r'\\d+', s)[1]))\n",
    "    #print(\"label_load def is play\")\n",
    "    return sort_label\n",
    "    \n",
    "\n",
    "class MyFERDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_path_base, label_path_base, train=None, transform=None):\n",
    "        super(MyFERDataset, self).__init__()\n",
    "        \n",
    "        if train == True:\n",
    "            self.img_path = img_path_base+'/train_set/images/'\n",
    "            self.label_path = label_path_base+'/train_set/annotations/'\n",
    "        else:\n",
    "            self.img_path = img_path_base+'/val_set/images/'\n",
    "            self.label_path = label_path_base+'/val_set/annotations/'\n",
    "\n",
    "        self.img = img_load(self.img_path)\n",
    "        self.label = label_load(self.label_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_read = io.imread(self.img[idx]) \n",
    "        label_read = np.load(self.label[idx])\n",
    "        label_read = label_read.astype(np.int64)\n",
    "        label_tr = torch.from_numpy(label_read)\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            img_tr = self.transform(img_read)\n",
    "        \n",
    "        \n",
    "        return img_tr, label_tr\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    if __name__ == \"__main__\":\n",
    "        print('hi, i\\'m main')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = tr.Compose([tr.ToTensor(),\n",
    "                              tr.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "transform_test = tr.Compose([tr.ToTensor()])\n",
    "\n",
    "\n",
    "train_dataset = MyFERDataset(img_path_base = path,\n",
    "                              label_path_base = path,\n",
    "                              train=True,\n",
    "                              transform=transform_train)\n",
    "test_dataset = MyFERDataset(img_path_base = path,\n",
    "                              label_path_base = path,\n",
    "                              train=False,\n",
    "                              transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "model = ResNet50()\n",
    "# ResNet18, ResNet34, ResNet50, ResNet101, ResNet152 중에 택일하여 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    }
   ],
   "source": [
    "model.apply(init_weights)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epoch = 200\n",
    "model_name = 'ResNet_FERtest_delete_plz.pth'\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_loss = 0\n",
    "valid_loss = 0\n",
    "correct = 0\n",
    "total_cnt = 0\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== 1 epoch of 200 ======\n",
      "tensor([0, 0, 4, 0, 2, 5, 6, 0, 7, 7, 6, 1, 4, 2, 7, 4, 2, 4, 2, 2, 7, 3, 0, 7,\n",
      "        1, 3, 2, 5, 7, 2, 7, 3], device='cuda:0') is batch[1]\n",
      "******************batch[1]****************\n",
      "\n",
      "<class 'torch.Tensor'> is batch[1]'s type\n",
      "****************batch[1]'s type******************\n",
      "\n",
      "torch.Size([32]) is batch[1].shape\n",
      "*****************batch[1].shape*****************\n",
      "\n",
      "tensor([[ 5.7233e-01,  1.0986e+00,  6.3732e-01,  4.3718e-01,  3.0287e-03,\n",
      "          8.5802e-01, -3.5717e-02,  1.2701e+00, -4.6271e+00, -3.2598e+00],\n",
      "        [ 5.8493e-01,  6.8440e-01,  6.3496e-01,  4.4948e-01,  5.2556e-01,\n",
      "          6.2652e-01,  1.0141e-01,  1.0641e+00, -4.8069e+00, -3.3459e+00],\n",
      "        [ 4.5936e-01,  8.0601e-02,  8.3221e-01,  4.6567e-01,  1.2426e+00,\n",
      "          5.9155e-01,  2.9897e-01,  4.8418e-01, -4.9909e+00, -3.4650e+00],\n",
      "        [ 4.0544e-01,  4.2018e-01,  7.3358e-01,  5.0741e-01,  8.6701e-01,\n",
      "          6.4301e-01,  2.3439e-01,  6.9178e-01, -4.8304e+00, -3.3644e+00],\n",
      "        [ 1.0757e+00, -8.7244e-01,  1.0266e+00,  8.3326e-01,  1.7175e+00,\n",
      "          1.2960e+00, -4.0598e-01,  1.3537e+00, -1.5409e+01, -8.3065e+00],\n",
      "        [ 6.1534e-01,  8.5882e-01,  8.1077e-01,  6.7877e-01,  2.2579e-01,\n",
      "          1.0244e+00, -1.8347e-01,  1.1504e+00, -6.5059e+00, -4.2235e+00],\n",
      "        [ 4.5080e-01,  2.1109e-01,  8.2261e-01,  4.8711e-01,  1.0982e+00,\n",
      "          6.3317e-01,  2.6850e-01,  5.7147e-01, -4.9807e+00, -3.4387e+00],\n",
      "        [ 6.1993e-01,  9.3426e-01,  7.0904e-01,  3.7514e-01,  1.9421e-01,\n",
      "          8.1998e-01,  1.0390e-02,  1.1219e+00, -4.6827e+00, -3.2986e+00],\n",
      "        [ 3.6619e-01,  7.7878e-01,  7.0364e-01,  5.2643e-01,  4.2492e-01,\n",
      "          8.1863e-01,  1.4752e-01,  9.4294e-01, -4.7492e+00, -3.2855e+00],\n",
      "        [ 4.3141e-01,  7.2375e-01,  6.9410e-01,  5.1895e-01,  4.9624e-01,\n",
      "          7.5281e-01,  1.3119e-01,  9.6728e-01, -4.8045e+00, -3.3340e+00],\n",
      "        [ 5.8460e-01,  1.0078e-02,  1.0031e+00,  7.2311e-01,  1.0325e+00,\n",
      "          9.9586e-01, -8.3181e-03,  6.0689e-01, -7.9753e+00, -4.8631e+00],\n",
      "        [ 5.7161e-01,  7.9527e-01,  6.5840e-01,  4.5354e-01,  4.0984e-01,\n",
      "          7.6639e-01,  3.6579e-02,  1.0474e+00, -4.8120e+00, -3.3767e+00],\n",
      "        [ 5.5398e-01,  4.1700e-01,  6.4238e-01,  5.1818e-01,  8.1002e-01,\n",
      "          5.5222e-01,  2.2959e-01,  7.9870e-01, -4.8022e+00, -3.3096e+00],\n",
      "        [ 5.3725e-01,  7.3331e-01,  7.3210e-01,  4.8089e-01,  4.8429e-01,\n",
      "          7.0424e-01,  5.7837e-02,  1.0340e+00, -4.8797e+00, -3.4049e+00],\n",
      "        [ 5.2595e-01,  7.1363e-01,  6.7034e-01,  4.7396e-01,  4.8370e-01,\n",
      "          7.4514e-01,  9.1920e-02,  9.7301e-01, -4.7902e+00, -3.3415e+00],\n",
      "        [ 4.4053e-01, -3.3606e-02,  8.7317e-01,  4.6000e-01,  1.3815e+00,\n",
      "          5.5106e-01,  3.6328e-01,  3.9151e-01, -5.0386e+00, -3.4705e+00],\n",
      "        [ 3.6682e-01,  5.3761e-01,  7.6624e-01,  5.2060e-01,  7.1084e-01,\n",
      "          7.6679e-01,  1.9452e-01,  7.9191e-01, -4.8378e+00, -3.3376e+00],\n",
      "        [ 5.4450e-01, -2.0459e-01,  1.0644e+00,  8.7368e-01,  1.6901e+00,\n",
      "          6.7581e-01, -1.3276e-01,  3.8685e-01, -8.1594e+00, -4.9711e+00],\n",
      "        [ 3.6038e-01,  1.0268e+00,  6.9114e-01,  5.3170e-01,  1.1723e-01,\n",
      "          9.0578e-01,  7.8508e-02,  1.1386e+00, -4.6563e+00, -3.2154e+00],\n",
      "        [ 3.4935e-01,  4.6327e-01,  8.2892e-01,  5.0262e-01,  7.9932e-01,\n",
      "          7.8026e-01,  2.0926e-01,  7.0351e-01, -4.8663e+00, -3.3650e+00],\n",
      "        [ 5.3523e-01,  5.4952e-01,  7.1797e-01,  4.5398e-01,  6.7728e-01,\n",
      "          7.1398e-01,  1.3403e-01,  8.5056e-01, -4.8630e+00, -3.3955e+00],\n",
      "        [ 3.9762e-01,  9.6134e-01,  6.9870e-01,  5.3270e-01,  2.0621e-01,\n",
      "          9.0373e-01,  7.6175e-02,  1.0842e+00, -4.7254e+00, -3.2812e+00],\n",
      "        [ 4.2951e+00, -6.1603e+00,  1.2698e+00,  1.3009e+00,  6.6420e+00,\n",
      "          3.8325e+00, -3.5735e+00,  5.0712e+00, -5.9606e+01, -2.9881e+01],\n",
      "        [ 6.5989e-01,  3.6684e-01,  6.1491e-01,  4.3285e-01,  8.4237e-01,\n",
      "          5.2220e-01,  1.8966e-01,  7.7616e-01, -4.7964e+00, -3.3246e+00],\n",
      "        [ 4.1888e-01,  4.0673e-01,  7.7726e-01,  5.5162e-01,  8.7125e-01,\n",
      "          6.6067e-01,  2.1639e-01,  7.8920e-01, -4.9645e+00, -3.4351e+00],\n",
      "        [ 5.0435e-01,  3.2006e-01,  7.1486e-01,  4.8524e-01,  9.3930e-01,\n",
      "          5.9511e-01,  2.2687e-01,  6.6752e-01, -4.8488e+00, -3.3576e+00],\n",
      "        [ 3.4897e-01,  5.0440e-01,  8.0863e-01,  5.2552e-01,  7.5680e-01,\n",
      "          7.7146e-01,  2.0905e-01,  7.2195e-01, -4.8569e+00, -3.3621e+00],\n",
      "        [ 3.8753e-01,  3.6746e-02,  9.3407e-01,  4.7809e-01,  1.2554e+00,\n",
      "          7.1964e-01,  3.2092e-01,  4.4691e-01, -5.0414e+00, -3.4889e+00],\n",
      "        [ 5.6603e-01,  9.1252e-01,  6.4438e-01,  4.6859e-01,  2.5075e-01,\n",
      "          8.1202e-01,  2.6550e-02,  1.1091e+00, -4.7774e+00, -3.3451e+00],\n",
      "        [ 5.6360e-01,  7.8769e-01,  7.0821e-01,  4.3314e-01,  3.6138e-01,\n",
      "          7.7958e-01,  7.5350e-02,  1.0267e+00, -4.7429e+00, -3.3218e+00],\n",
      "        [ 5.2785e-01,  6.5136e-01,  6.3966e-01,  4.8384e-01,  5.6602e-01,\n",
      "          6.8376e-01,  1.2535e-01,  9.4340e-01, -4.7935e+00, -3.3377e+00],\n",
      "        [ 3.5801e-01,  5.3608e-01,  7.8001e-01,  5.3487e-01,  7.2056e-01,\n",
      "          7.6968e-01,  2.0138e-01,  7.7493e-01, -4.8702e+00, -3.3717e+00]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>) is logits\n",
      "****************logits************\n",
      "\n",
      "<class 'torch.Tensor'> is logits's type\n",
      "***************logits's type*************\n",
      "\n",
      "torch.Size([32, 10]) is logits's shape\n",
      "***************logits's shape*************\n",
      "\n",
      "tensor([1.2701, 1.0641, 1.2426, 0.8670, 1.7175, 1.1504, 1.0982, 1.1219, 0.9429,\n",
      "        0.9673, 1.0325, 1.0474, 0.8100, 1.0340, 0.9730, 1.3815, 0.7919, 1.6901,\n",
      "        1.1386, 0.8289, 0.8506, 1.0842, 6.6420, 0.8424, 0.8712, 0.9393, 0.8086,\n",
      "        1.2554, 1.1091, 1.0267, 0.9434, 0.7800], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>) is _\n",
      "***************_*************\n",
      "\n",
      "tensor([7, 7, 4, 4, 4, 7, 4, 7, 7, 7, 4, 7, 4, 7, 7, 4, 7, 4, 7, 2, 7, 7, 4, 4,\n",
      "        4, 4, 2, 4, 7, 7, 7, 2], device='cuda:0') is predict\n",
      "**************predict**************\n",
      "\n",
      "tensor([6, 0, 2, 2, 1, 7, 7, 7, 7, 3, 6, 3, 1, 5, 5, 1, 4, 3, 5, 3, 5, 7, 0, 0,\n",
      "        3, 3, 4, 1, 3, 1, 2, 1], device='cuda:0') is batch[1]\n",
      "******************batch[1]****************\n",
      "\n",
      "<class 'torch.Tensor'> is batch[1]'s type\n",
      "****************batch[1]'s type******************\n",
      "\n",
      "torch.Size([32]) is batch[1].shape\n",
      "*****************batch[1].shape*****************\n",
      "\n",
      "tensor([[ 6.2636e-01,  3.3962e-01,  9.3278e-01,  6.9852e-01,  8.4474e-01,\n",
      "          7.5481e-01,  2.6944e-01,  6.7394e-01, -5.7337e+00, -3.8772e+00],\n",
      "        [ 4.8088e-01,  4.5698e-02,  1.0012e+00,  6.0198e-01,  1.3254e+00,\n",
      "          7.3697e-01,  3.7243e-01,  4.6176e-01, -5.6264e+00, -3.8678e+00],\n",
      "        [ 1.3478e+00, -7.4056e-01,  9.0376e-01,  8.7944e-01,  1.7429e+00,\n",
      "          1.1449e+00, -1.7606e-01,  8.1392e-01, -1.3891e+01, -7.7014e+00],\n",
      "        [ 5.3956e+00, -6.2284e+00,  2.0799e-01,  1.4843e+00,  7.3813e+00,\n",
      "          2.6439e+00, -2.7614e+00,  3.6147e+00, -5.5403e+01, -2.7967e+01],\n",
      "        [ 7.1543e-01,  1.2538e+00,  8.0051e-01,  4.8226e-01, -1.4717e-01,\n",
      "          1.0113e+00, -5.9812e-02,  1.3814e+00, -5.1562e+00, -3.6089e+00],\n",
      "        [ 6.0884e-01,  6.5781e-01,  7.2159e-01,  6.2837e-01,  6.5767e-01,\n",
      "          6.7925e-01,  1.6390e-01,  1.0476e+00, -5.4396e+00, -3.7459e+00],\n",
      "        [ 4.2823e-01,  9.1625e-01,  8.2026e-01,  6.4173e-01,  3.1689e-01,\n",
      "          9.2309e-01,  1.5486e-01,  1.0505e+00, -5.2455e+00, -3.6115e+00],\n",
      "        [ 4.3773e-01, -4.7050e-02,  1.0244e+00,  6.0748e-01,  1.4558e+00,\n",
      "          6.9695e-01,  4.3740e-01,  3.8927e-01, -5.6631e+00, -3.8984e+00],\n",
      "        [ 5.2410e-01,  6.0742e-01,  8.8922e-01,  6.9358e-01,  7.1387e-01,\n",
      "          7.9931e-01,  1.7014e-01,  8.9679e-01, -5.5615e+00, -3.8493e+00],\n",
      "        [ 4.0878e-01,  6.9915e-01,  9.2722e-01,  6.2696e-01,  5.5629e-01,\n",
      "          9.3154e-01,  1.8361e-01,  8.8708e-01, -5.3466e+00, -3.6934e+00],\n",
      "        [ 4.6290e-01,  4.3699e-02,  1.0222e+00,  6.1009e-01,  1.3050e+00,\n",
      "          7.7977e-01,  3.9321e-01,  4.6125e-01, -5.6379e+00, -3.8833e+00],\n",
      "        [ 3.8257e-01,  1.0454e+00,  8.6886e-01,  6.3857e-01,  1.4447e-01,\n",
      "          1.0204e+00,  1.1844e-01,  1.1157e+00, -5.2057e+00, -3.5885e+00],\n",
      "        [ 5.6400e-01,  5.9343e-01,  8.3098e-01,  6.1514e-01,  6.8017e-01,\n",
      "          7.7902e-01,  2.0236e-01,  9.3536e-01, -5.4316e+00, -3.7469e+00],\n",
      "        [ 5.2942e-01,  1.0706e+00,  8.1764e-01,  5.9644e-01,  1.0690e-01,\n",
      "          1.0188e+00,  4.7186e-02,  1.1935e+00, -5.2715e+00, -3.6616e+00],\n",
      "        [ 3.7542e-01,  8.4252e-01,  9.3113e-01,  6.4377e-01,  3.9635e-01,\n",
      "          8.9428e-01,  1.8367e-01,  1.0933e+00, -5.3611e+00, -3.6786e+00],\n",
      "        [ 2.7428e+00, -2.4478e+00,  6.1676e-01,  9.6444e-01,  3.3787e+00,\n",
      "          1.5857e+00, -1.0140e+00,  1.5813e+00, -2.6773e+01, -1.4024e+01],\n",
      "        [ 4.2511e-01,  2.2747e-01,  9.7314e-01,  6.3810e-01,  1.1413e+00,\n",
      "          7.8033e-01,  3.2671e-01,  5.6508e-01, -5.5561e+00, -3.8222e+00],\n",
      "        [ 5.8190e-01,  1.0394e+00,  7.5974e-01,  5.9563e-01,  1.5516e-01,\n",
      "          9.3987e-01,  3.9587e-02,  1.1965e+00, -5.2689e+00, -3.6621e+00],\n",
      "        [ 4.9771e-01,  8.2510e-01,  8.1826e-01,  6.0207e-01,  4.3544e-01,\n",
      "          8.9820e-01,  1.3822e-01,  9.9786e-01, -5.3368e+00, -3.6982e+00],\n",
      "        [ 5.1019e-01,  4.6541e-01,  8.6014e-01,  6.2863e-01,  8.5701e-01,\n",
      "          7.6753e-01,  2.4629e-01,  7.4999e-01, -5.4450e+00, -3.7502e+00],\n",
      "        [ 4.5346e-01,  3.1722e-01,  9.6873e-01,  6.1769e-01,  9.8273e-01,\n",
      "          8.2747e-01,  2.9443e-01,  6.7018e-01, -5.5241e+00, -3.8062e+00],\n",
      "        [ 6.3131e-01,  3.8143e-01,  6.5691e-01,  6.4943e-01,  9.6676e-01,\n",
      "          4.9963e-01,  3.0275e-01,  8.3275e-01, -5.3941e+00, -3.7009e+00],\n",
      "        [ 4.5309e-01,  7.9690e-01,  8.1579e-01,  6.2676e-01,  4.6863e-01,\n",
      "          8.8425e-01,  1.7150e-01,  9.5069e-01, -5.3012e+00, -3.6438e+00],\n",
      "        [ 7.2232e-01,  6.0309e-01,  6.7414e-01,  5.6116e-01,  6.7158e-01,\n",
      "          6.3585e-01,  1.9878e-01,  9.4324e-01, -5.3301e+00, -3.6914e+00],\n",
      "        [ 6.8651e-01,  1.1160e+00,  7.3865e-01,  5.3066e-01,  4.8032e-02,\n",
      "          9.2814e-01, -2.6186e-02,  1.3084e+00, -5.2381e+00, -3.6533e+00],\n",
      "        [ 6.5080e-01,  1.1214e+00,  6.6508e-01,  5.5282e-01,  8.3902e-02,\n",
      "          8.7843e-01, -1.7811e-02,  1.3228e+00, -5.2351e+00, -3.6516e+00],\n",
      "        [ 6.2812e-01,  7.3814e-02,  8.9691e-01,  7.3104e-01,  1.4225e+00,\n",
      "          5.2425e-01,  2.8794e-01,  4.9854e-01, -6.1928e+00, -4.1642e+00],\n",
      "        [ 5.0451e-01,  9.2860e-01,  7.9342e-01,  6.2591e-01,  2.9044e-01,\n",
      "          8.8491e-01,  1.1157e-01,  1.1340e+00, -5.2812e+00, -3.6518e+00],\n",
      "        [ 5.8633e-01,  5.3344e-01,  8.7738e-01,  5.6599e-01,  7.5764e-01,\n",
      "          8.0404e-01,  1.8646e-01,  8.3937e-01, -5.4600e+00, -3.7864e+00],\n",
      "        [ 6.6536e-01,  1.0657e+00,  8.1454e-01,  5.0108e-01,  9.8092e-02,\n",
      "          9.5917e-01,  9.5040e-03,  1.2366e+00, -5.2397e+00, -3.6577e+00],\n",
      "        [ 3.7256e-01, -3.4941e-01,  1.0895e+00,  6.2946e-01,  1.8173e+00,\n",
      "          6.4021e-01,  5.3827e-01,  1.9466e-01, -5.7894e+00, -3.9692e+00],\n",
      "        [ 4.4849e-01,  9.4354e-01,  8.6004e-01,  6.3541e-01,  2.7570e-01,\n",
      "          9.8821e-01,  1.0339e-01,  1.0908e+00, -5.2959e+00, -3.6736e+00]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>) is logits\n",
      "****************logits************\n",
      "\n",
      "<class 'torch.Tensor'> is logits's type\n",
      "***************logits's type*************\n",
      "\n",
      "torch.Size([32, 10]) is logits's shape\n",
      "***************logits's shape*************\n",
      "\n",
      "tensor([0.9328, 1.3254, 1.7429, 7.3813, 1.3814, 1.0476, 1.0505, 1.4558, 0.8968,\n",
      "        0.9315, 1.3050, 1.1157, 0.9354, 1.1935, 1.0933, 3.3787, 1.1413, 1.1965,\n",
      "        0.9979, 0.8601, 0.9827, 0.9668, 0.9507, 0.9432, 1.3084, 1.3228, 1.4225,\n",
      "        1.1340, 0.8774, 1.2366, 1.8173, 1.0908], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>) is _\n",
      "***************_*************\n",
      "\n",
      "tensor([2, 4, 4, 4, 7, 7, 7, 4, 7, 5, 4, 7, 7, 7, 7, 4, 4, 7, 7, 2, 4, 4, 7, 7,\n",
      "        7, 7, 4, 7, 2, 7, 4, 7], device='cuda:0') is predict\n",
      "**************predict**************\n",
      "\n",
      "tensor([4, 4, 3, 1, 2, 2, 2, 2, 2, 2, 2, 4, 1, 1, 2, 0, 6, 4, 1, 3, 1, 0, 2, 5,\n",
      "        7, 0, 1, 6, 6, 3, 5, 5], device='cuda:0') is batch[1]\n",
      "******************batch[1]****************\n",
      "\n",
      "<class 'torch.Tensor'> is batch[1]'s type\n",
      "****************batch[1]'s type******************\n",
      "\n",
      "torch.Size([32]) is batch[1].shape\n",
      "*****************batch[1].shape*****************\n",
      "\n",
      "tensor([[ 9.4590e-01,  3.7885e-01,  1.1348e+00,  8.8823e-01,  1.0038e+00,\n",
      "          9.1282e-01,  2.4942e-01,  6.1010e-01, -8.3062e+00, -5.3131e+00],\n",
      "        [ 8.2429e-01,  4.3701e-01,  7.6848e-01,  8.2905e-01,  1.0076e+00,\n",
      "          6.2679e-01,  3.8021e-01,  9.1493e-01, -6.3164e+00, -4.3284e+00],\n",
      "        [ 6.9159e-01,  8.2241e-01,  1.0040e+00,  7.8535e-01,  5.3114e-01,\n",
      "          1.0130e+00,  2.0313e-01,  1.0832e+00, -6.3796e+00, -4.3905e+00],\n",
      "        [ 7.2639e-01,  5.6301e-01,  1.1268e+00,  9.5025e-01,  9.5165e-01,\n",
      "          8.5349e-01,  2.3452e-01,  8.2693e-01, -7.1782e+00, -4.8337e+00],\n",
      "        [ 6.5551e-01,  6.5943e-01,  1.0203e+00,  8.0146e-01,  7.8512e-01,\n",
      "          9.6182e-01,  2.8118e-01,  9.3473e-01, -6.4854e+00, -4.4705e+00],\n",
      "        [ 5.8239e-01,  9.7011e-01,  1.1052e+00,  9.0996e-01,  3.4351e-01,\n",
      "          1.0678e+00,  1.5145e-01,  1.1763e+00, -6.4776e+00, -4.4500e+00],\n",
      "        [ 4.6069e-01,  6.0874e-01,  1.1329e+00,  8.6670e-01,  8.3764e-01,\n",
      "          1.0313e+00,  3.3807e-01,  8.2178e-01, -6.4625e+00, -4.4194e+00],\n",
      "        [ 3.8266e+00, -2.7681e+00,  1.3594e+00,  1.2871e+00,  3.7313e+00,\n",
      "          1.4238e+00, -1.2869e+00,  1.8138e+00, -3.4830e+01, -1.7984e+01],\n",
      "        [ 5.8415e-01,  2.9247e-01,  1.1217e+00,  9.2284e-01,  1.1900e+00,\n",
      "          7.9103e-01,  4.2727e-01,  7.2175e-01, -6.7238e+00, -4.6012e+00],\n",
      "        [ 5.1197e-01,  9.3290e-01,  1.0780e+00,  8.6484e-01,  4.4508e-01,\n",
      "          1.1173e+00,  1.9982e-01,  1.0580e+00, -6.3548e+00, -4.3680e+00],\n",
      "        [ 4.8729e-01,  1.0970e+00,  1.0547e+00,  8.5852e-01,  2.5745e-01,\n",
      "          1.1651e+00,  1.6434e-01,  1.1566e+00, -6.2574e+00, -4.3000e+00],\n",
      "        [ 6.2823e-01,  4.1680e-01,  9.1680e-01,  8.6792e-01,  1.1166e+00,\n",
      "          7.7666e-01,  4.2395e-01,  7.6306e-01, -6.4908e+00, -4.4613e+00],\n",
      "        [ 5.8095e-01,  6.6830e-01,  1.0237e+00,  8.5153e-01,  7.9476e-01,\n",
      "          9.7345e-01,  2.8633e-01,  9.2709e-01, -6.4751e+00, -4.4496e+00],\n",
      "        [ 5.4220e-01,  1.1425e+00,  1.0482e+00,  8.3228e-01,  1.7077e-01,\n",
      "          1.1970e+00,  1.3561e-01,  1.2167e+00, -6.2333e+00, -4.2944e+00],\n",
      "        [ 4.6473e-01,  9.8553e-01,  1.0737e+00,  8.2464e-01,  3.9538e-01,\n",
      "          1.1215e+00,  2.0218e-01,  1.0746e+00, -6.2973e+00, -4.3278e+00],\n",
      "        [ 3.3395e+00, -1.8412e+00,  1.3184e+00,  1.1286e+00,  2.7503e+00,\n",
      "          1.3700e+00, -1.0927e+00,  1.6609e+00, -2.8891e+01, -1.5125e+01],\n",
      "        [ 4.7519e-01,  5.5987e-01,  1.1386e+00,  8.6073e-01,  8.8318e-01,\n",
      "          1.0081e+00,  3.6152e-01,  8.1976e-01, -6.4686e+00, -4.4355e+00],\n",
      "        [ 5.2638e-01, -1.6083e-01,  1.2204e+00,  8.3704e-01,  1.7026e+00,\n",
      "          8.2814e-01,  5.9601e-01,  3.9525e-01, -6.7755e+00, -4.6321e+00],\n",
      "        [ 5.7440e-01,  1.4263e-01,  1.0921e+00,  8.4690e-01,  1.3808e+00,\n",
      "          8.2248e-01,  4.7516e-01,  5.7717e-01, -6.6369e+00, -4.5337e+00],\n",
      "        [ 6.2737e-01,  8.2260e-01,  1.0082e+00,  8.3788e-01,  6.0145e-01,\n",
      "          1.0178e+00,  2.1575e-01,  1.0397e+00, -6.4545e+00, -4.4362e+00],\n",
      "        [ 6.9700e-01,  3.7009e-01,  9.5556e-01,  8.2663e-01,  1.1282e+00,\n",
      "          7.5904e-01,  3.9876e-01,  7.8422e-01, -6.5357e+00, -4.4825e+00],\n",
      "        [ 5.2297e+00, -4.1508e+00,  1.3218e+00,  1.5034e+00,  5.0932e+00,\n",
      "          1.6452e+00, -2.0159e+00,  2.5656e+00, -4.6567e+01, -2.3716e+01],\n",
      "        [ 4.7448e-01,  1.0384e-01,  1.1891e+00,  8.9759e-01,  1.4487e+00,\n",
      "          8.7712e-01,  5.0032e-01,  5.2248e-01, -6.6873e+00, -4.5647e+00],\n",
      "        [ 8.5575e-01,  1.4472e+00,  9.2011e-01,  7.1001e-01, -2.0537e-01,\n",
      "          1.1020e+00, -4.0965e-02,  1.6029e+00, -6.1420e+00, -4.2640e+00],\n",
      "        [ 5.2577e-01,  1.0726e+00,  1.0902e+00,  8.3252e-01,  2.4427e-01,\n",
      "          1.2205e+00,  1.4670e-01,  1.1792e+00, -6.2968e+00, -4.3295e+00],\n",
      "        [ 7.6731e-01,  9.1634e-01,  1.0378e+00,  7.1247e-01,  4.4402e-01,\n",
      "          1.0352e+00,  1.6674e-01,  1.1147e+00, -6.3528e+00, -4.3902e+00],\n",
      "        [ 8.1072e-01,  8.9659e-01,  7.7531e-01,  7.5048e-01,  5.2463e-01,\n",
      "          8.2157e-01,  1.7742e-01,  1.1644e+00, -6.2709e+00, -4.3285e+00],\n",
      "        [ 4.6684e-01,  5.0647e-01,  1.1252e+00,  9.0252e-01,  9.5364e-01,\n",
      "          1.0218e+00,  3.7183e-01,  7.6076e-01, -6.5313e+00, -4.4557e+00],\n",
      "        [ 7.5882e-01,  1.3839e+00,  8.5392e-01,  7.6223e-01, -1.0584e-01,\n",
      "          1.1386e+00, -5.8120e-03,  1.4436e+00, -6.1965e+00, -4.2931e+00],\n",
      "        [ 7.6987e-01,  1.0490e+00,  9.1658e-01,  7.5473e-01,  2.8299e-01,\n",
      "          1.0241e+00,  9.9579e-02,  1.2430e+00, -6.3051e+00, -4.3682e+00],\n",
      "        [ 6.2757e-01,  8.0316e-01,  1.0084e+00,  8.2269e-01,  6.2755e-01,\n",
      "          1.0131e+00,  2.2305e-01,  1.0138e+00, -6.4540e+00, -4.4539e+00],\n",
      "        [ 7.6074e-01,  4.4455e-01,  9.4949e-01,  7.3419e-01,  9.9754e-01,\n",
      "          8.3675e-01,  3.1385e-01,  8.2497e-01, -6.4635e+00, -4.4401e+00]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>) is logits\n",
      "****************logits************\n",
      "\n",
      "<class 'torch.Tensor'> is logits's type\n",
      "***************logits's type*************\n",
      "\n",
      "torch.Size([32, 10]) is logits's shape\n",
      "***************logits's shape*************\n",
      "\n",
      "tensor([1.1348, 1.0076, 1.0832, 1.1268, 1.0203, 1.1763, 1.1329, 3.8266, 1.1900,\n",
      "        1.1173, 1.1651, 1.1166, 1.0237, 1.2167, 1.1215, 3.3395, 1.1386, 1.7026,\n",
      "        1.3808, 1.0397, 1.1282, 5.2297, 1.4487, 1.6029, 1.2205, 1.1147, 1.1644,\n",
      "        1.1252, 1.4436, 1.2430, 1.0138, 0.9975], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>) is _\n",
      "***************_*************\n",
      "\n",
      "tensor([2, 4, 7, 2, 2, 7, 2, 0, 4, 5, 5, 4, 2, 7, 5, 0, 2, 4, 4, 7, 4, 0, 4, 7,\n",
      "        5, 7, 7, 2, 7, 7, 7, 4], device='cuda:0') is predict\n",
      "**************predict**************\n",
      "\n",
      "tensor([5, 1, 0, 5, 2, 0, 1, 3, 1, 4, 1, 0, 7, 4, 0, 5, 2, 7, 7, 0, 0, 4, 4, 6,\n",
      "        4, 5, 2, 1, 4, 1, 5, 0], device='cuda:0') is batch[1]\n",
      "******************batch[1]****************\n",
      "\n",
      "<class 'torch.Tensor'> is batch[1]'s type\n",
      "****************batch[1]'s type******************\n",
      "\n",
      "torch.Size([32]) is batch[1].shape\n",
      "*****************batch[1].shape*****************\n",
      "\n",
      "tensor([[ 3.3826e-01,  4.7621e-01,  9.2138e-01,  7.0234e-01,  7.0509e-01,\n",
      "          7.6255e-01,  3.1896e-01,  6.4367e-01, -5.1287e+00, -3.5307e+00],\n",
      "        [ 9.1314e-01,  7.8785e-01,  9.2794e-01,  8.1230e-01,  2.1334e-01,\n",
      "          8.1465e-01, -1.0995e-01,  9.0389e-01, -7.3240e+00, -4.6335e+00],\n",
      "        [ 1.3304e+00,  2.3682e-01,  1.3353e+00,  8.3895e-01,  3.6152e-01,\n",
      "          9.8689e-01, -6.7000e-02,  8.1630e-01, -1.0751e+01, -6.0648e+00],\n",
      "        [ 5.2458e-01,  4.9970e-01,  7.4001e-01,  7.3654e-01,  6.5451e-01,\n",
      "          5.8691e-01,  2.7964e-01,  7.6305e-01, -5.0922e+00, -3.5121e+00],\n",
      "        [ 2.4853e-01,  2.7016e-01,  1.0220e+00,  7.3702e-01,  9.4564e-01,\n",
      "          7.6678e-01,  3.9944e-01,  4.5709e-01, -5.2410e+00, -3.6014e+00],\n",
      "        [ 1.1453e+00, -2.6697e-01,  1.5517e+00,  9.0105e-01,  1.0336e+00,\n",
      "          8.4606e-01,  1.6981e-01,  2.0544e-01, -1.0652e+01, -6.0938e+00],\n",
      "        [ 5.9250e-01,  7.1456e-01,  6.9949e-01,  6.0093e-01,  4.6440e-01,\n",
      "          6.7292e-01,  1.8160e-01,  8.6924e-01, -5.0674e+00, -3.5100e+00],\n",
      "        [ 4.4177e-01, -2.8070e-01,  1.1879e+00,  8.8584e-01,  1.5176e+00,\n",
      "          4.4652e-01,  5.6101e-01,  1.5504e-01, -6.6138e+00, -4.2358e+00],\n",
      "        [ 5.0779e-01,  9.0839e-01,  7.1551e-01,  7.0852e-01,  1.8587e-01,\n",
      "          8.0100e-01,  1.4178e-01,  9.6782e-01, -4.9527e+00, -3.4191e+00],\n",
      "        [ 2.1332e-01, -8.2140e-01,  1.0981e+00,  6.8826e-01,  2.2846e+00,\n",
      "          3.5587e-01,  8.9217e-01, -1.1263e-01, -5.6664e+00, -3.8690e+00],\n",
      "        [ 5.9097e-01,  1.2028e+00,  7.8843e-01,  6.3631e-01, -2.4711e-01,\n",
      "          9.8765e-01, -1.7612e-04,  1.1825e+00, -4.8348e+00, -3.3576e+00],\n",
      "        [ 5.4862e-01,  5.5229e-01,  8.3322e-01,  6.3512e-01,  5.5083e-01,\n",
      "          7.3457e-01,  2.3872e-01,  8.0899e-01, -5.1425e+00, -3.5468e+00],\n",
      "        [ 7.1496e+00, -4.8487e+00,  3.4015e+00,  1.7001e+00,  4.4453e+00,\n",
      "          9.2114e-01, -2.4281e+00,  2.2795e+00, -5.3589e+01, -2.6840e+01],\n",
      "        [ 1.2318e+00, -5.2539e-02,  1.2048e+00,  8.7376e-01,  8.5847e-01,\n",
      "          7.4794e-01,  1.1006e-01,  5.4534e-01, -1.0401e+01, -5.9367e+00],\n",
      "        [ 4.2668e-01,  4.3752e-01,  8.2051e-01,  7.0383e-01,  7.9447e-01,\n",
      "          6.8784e-01,  3.1526e-01,  6.3218e-01, -5.1852e+00, -3.6007e+00],\n",
      "        [ 3.9972e-01,  9.1137e-01,  8.7642e-01,  6.9964e-01,  1.3988e-01,\n",
      "          9.2895e-01,  1.5030e-01,  9.3552e-01, -4.9737e+00, -3.4345e+00],\n",
      "        [ 3.7172e-01,  1.0097e+00,  7.9973e-01,  6.9447e-01,  4.3528e-03,\n",
      "          9.2134e-01,  1.1092e-01,  1.0199e+00, -4.8423e+00, -3.3273e+00],\n",
      "        [ 6.4986e-01,  1.1039e+00,  6.6578e-01,  6.1192e-01, -8.3884e-02,\n",
      "          8.5165e-01,  3.0736e-03,  1.1719e+00, -4.9269e+00, -3.4379e+00],\n",
      "        [ 4.7759e-01,  1.0618e+00,  8.6576e-01,  6.7011e-01, -7.2975e-02,\n",
      "          9.9395e-01,  7.5524e-02,  1.0844e+00, -4.9197e+00, -3.3943e+00],\n",
      "        [ 4.9959e-01, -8.6423e-02,  9.1951e-01,  8.3429e-01,  1.3960e+00,\n",
      "          3.1417e-01,  5.3212e-01,  3.3300e-01, -5.9156e+00, -3.8944e+00],\n",
      "        [ 5.9646e-01,  4.4087e-01,  8.7555e-01,  5.8752e-01,  7.2514e-01,\n",
      "          7.1843e-01,  2.6047e-01,  6.4703e-01, -5.1880e+00, -3.5965e+00],\n",
      "        [ 6.0095e-01,  9.8274e-01,  6.3570e-01,  6.5305e-01,  7.9653e-02,\n",
      "          7.7157e-01,  8.6502e-02,  1.0826e+00, -4.9048e+00, -3.4099e+00],\n",
      "        [ 2.7645e-01, -4.7998e-01,  1.0197e+00,  7.0850e-01,  1.9319e+00,\n",
      "          3.9518e-01,  7.5110e-01,  5.0720e-02, -5.5477e+00, -3.7894e+00],\n",
      "        [ 8.2217e-01,  6.1661e-01,  1.1915e+00,  8.0227e-01,  1.9329e-01,\n",
      "          1.0497e+00,  8.3684e-02,  7.1045e-01, -7.5455e+00, -4.6287e+00],\n",
      "        [ 4.0202e-01, -1.5349e-01,  9.8266e-01,  6.6737e-01,  1.4307e+00,\n",
      "          5.9058e-01,  5.5744e-01,  2.6510e-01, -5.4206e+00, -3.7311e+00],\n",
      "        [ 4.0486e-01,  6.2204e-01,  8.2867e-01,  7.2393e-01,  4.9202e-01,\n",
      "          8.2170e-01,  2.3264e-01,  7.8422e-01, -5.0891e+00, -3.5104e+00],\n",
      "        [ 3.2116e-01,  1.0098e+00,  9.1196e-01,  6.9273e-01,  2.6126e-02,\n",
      "          9.8098e-01,  1.1387e-01,  9.7269e-01, -4.8790e+00, -3.3530e+00],\n",
      "        [ 6.1166e-01,  5.5048e-01,  7.3117e-01,  7.2248e-01,  5.6205e-01,\n",
      "          5.6938e-01,  2.4240e-01,  9.2731e-01, -5.0841e+00, -3.4953e+00],\n",
      "        [ 4.2684e-01,  1.7834e-01,  8.7097e-01,  6.8443e-01,  1.1168e+00,\n",
      "          5.9358e-01,  4.4731e-01,  4.6454e-01, -5.2907e+00, -3.6516e+00],\n",
      "        [ 4.8020e-01,  9.4070e-01,  7.5658e-01,  6.9459e-01,  1.3885e-01,\n",
      "          8.5348e-01,  1.0083e-01,  9.8967e-01, -4.9646e+00, -3.4521e+00],\n",
      "        [ 2.9895e-01,  9.2188e-01,  9.2780e-01,  7.4325e-01,  9.2999e-02,\n",
      "          1.0024e+00,  1.2406e-01,  9.4228e-01, -4.9591e+00, -3.4141e+00],\n",
      "        [ 6.7353e-01,  1.2729e+00,  7.8327e-01,  5.9148e-01, -3.2499e-01,\n",
      "          1.0157e+00, -4.1438e-02,  1.2161e+00, -4.8518e+00, -3.3678e+00]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>) is logits\n",
      "****************logits************\n",
      "\n",
      "<class 'torch.Tensor'> is logits's type\n",
      "***************logits's type*************\n",
      "\n",
      "torch.Size([32, 10]) is logits's shape\n",
      "***************logits's shape*************\n",
      "\n",
      "tensor([0.9214, 0.9279, 1.3353, 0.7630, 1.0220, 1.5517, 0.8692, 1.5176, 0.9678,\n",
      "        2.2846, 1.2028, 0.8332, 7.1496, 1.2318, 0.8205, 0.9355, 1.0199, 1.1719,\n",
      "        1.0844, 1.3960, 0.8755, 1.0826, 1.9319, 1.1915, 1.4307, 0.8287, 1.0098,\n",
      "        0.9273, 1.1168, 0.9897, 1.0024, 1.2729], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>) is _\n",
      "***************_*************\n",
      "\n",
      "tensor([2, 2, 2, 7, 2, 2, 7, 4, 7, 4, 1, 2, 0, 0, 2, 7, 7, 7, 7, 4, 2, 7, 4, 2,\n",
      "        4, 2, 1, 7, 4, 7, 5, 1], device='cuda:0') is predict\n",
      "**************predict**************\n",
      "\n",
      "tensor([1, 2, 0, 1, 3, 2, 4, 4, 6, 2, 7, 3, 4, 4, 5, 6, 4, 7, 4, 0, 4, 1, 2, 2,\n",
      "        3, 2, 2, 3, 4, 2, 6, 6], device='cuda:0') is batch[1]\n",
      "******************batch[1]****************\n",
      "\n",
      "<class 'torch.Tensor'> is batch[1]'s type\n",
      "****************batch[1]'s type******************\n",
      "\n",
      "torch.Size([32]) is batch[1].shape\n",
      "*****************batch[1].shape*****************\n",
      "\n",
      "tensor([[ 7.0253e-01,  1.1648e+00,  8.8244e-01,  5.7280e-01, -2.3582e-01,\n",
      "          1.0078e+00,  2.0514e-02,  1.0372e+00, -4.8366e+00, -3.3631e+00],\n",
      "        [ 4.3944e-01,  1.0410e+00,  9.2843e-01,  7.2090e-01, -1.0180e-01,\n",
      "          1.0514e+00,  7.7461e-02,  9.6274e-01, -4.9433e+00, -3.4015e+00],\n",
      "        [ 7.3826e-01,  1.2385e+00,  7.3252e-01,  5.7396e-01, -3.1459e-01,\n",
      "          9.4988e-01, -5.5584e-03,  1.1532e+00, -4.7690e+00, -3.3349e+00],\n",
      "        [ 5.3079e-01,  1.2768e+00,  6.7836e-01,  6.8447e-01, -3.1382e-01,\n",
      "          8.6914e-01,  2.1646e-03,  1.2281e+00, -4.7495e+00, -3.2942e+00],\n",
      "        [ 3.7316e-01,  6.3450e-01,  8.0802e-01,  7.8595e-01,  4.9500e-01,\n",
      "          7.5729e-01,  2.2944e-01,  6.7760e-01, -5.0152e+00, -3.4643e+00],\n",
      "        [ 4.1514e-01,  1.5296e-01,  9.5359e-01,  7.2012e-01,  1.0847e+00,\n",
      "          6.4005e-01,  4.5009e-01,  3.9411e-01, -5.3007e+00, -3.6549e+00],\n",
      "        [ 2.5499e-01,  9.5712e-01,  1.0439e+00,  7.3702e-01, -1.3123e-02,\n",
      "          1.0458e+00,  1.2540e-01,  8.3689e-01, -4.8716e+00, -3.3276e+00],\n",
      "        [ 6.4534e-01,  1.6361e-01,  1.3022e+00,  9.5912e-01,  1.2278e+00,\n",
      "          2.0883e-01,  3.8349e-01,  2.8065e-01, -7.0093e+00, -4.5130e+00],\n",
      "        [ 6.6853e-01,  1.0984e+00,  7.6931e-01,  6.6214e-01, -8.7706e-02,\n",
      "          8.0722e-01,  4.7034e-02,  1.1925e+00, -4.9459e+00, -3.4364e+00],\n",
      "        [ 3.5121e-01,  9.8891e-01,  1.0400e+00,  7.7358e-01, -5.3167e-02,\n",
      "          9.8759e-01,  1.1625e-01,  9.6187e-01, -4.9358e+00, -3.4009e+00],\n",
      "        [ 6.4276e-01,  1.5721e+00,  6.5372e-01,  6.2132e-01, -7.4074e-01,\n",
      "          1.0466e+00, -1.1637e-01,  1.3755e+00, -4.5861e+00, -3.1928e+00],\n",
      "        [ 5.5470e-01,  7.9746e-01,  9.0368e-01,  7.2896e-01,  3.0632e-01,\n",
      "          7.1602e-01,  1.9312e-01,  7.8763e-01, -5.1387e+00, -3.5555e+00],\n",
      "        [ 1.6621e-01, -1.0308e+00,  1.1585e+00,  7.4982e-01,  2.5879e+00,\n",
      "          2.7300e-01,  9.9733e-01, -3.0996e-01, -5.7641e+00, -3.9340e+00],\n",
      "        [ 7.3644e+00, -4.3635e+00,  4.9399e+00,  1.4085e+00,  3.1717e+00,\n",
      "         -2.1882e-01, -2.0078e+00,  2.4711e+00, -5.4499e+01, -2.7312e+01],\n",
      "        [ 5.9486e-01,  9.2540e-01,  7.1570e-01,  6.7530e-01,  1.2563e-01,\n",
      "          8.0879e-01,  9.8588e-02,  9.2529e-01, -4.9551e+00, -3.4469e+00],\n",
      "        [ 4.3873e-01,  1.7082e-01,  9.7463e-01,  7.0008e-01,  1.0535e+00,\n",
      "          6.7665e-01,  4.5116e-01,  3.7796e-01, -5.2949e+00, -3.6501e+00],\n",
      "        [ 4.5356e-01,  8.3835e-01,  9.2381e-01,  7.9763e-01,  2.0170e-01,\n",
      "          8.4812e-01,  1.5006e-01,  9.1446e-01, -5.1540e+00, -3.5721e+00],\n",
      "        [ 5.1753e-01,  1.1053e+00,  7.7468e-01,  7.0883e-01, -1.3031e-01,\n",
      "          9.4063e-01,  5.8814e-02,  1.0393e+00, -4.8906e+00, -3.4021e+00],\n",
      "        [ 3.8527e-01,  6.7523e-01,  9.0859e-01,  7.6758e-01,  4.1528e-01,\n",
      "          8.5435e-01,  2.2348e-01,  6.8245e-01, -5.0726e+00, -3.4948e+00],\n",
      "        [ 4.7915e-01,  5.5018e-02,  7.7762e-01,  7.5929e-01,  1.1900e+00,\n",
      "          4.2320e-01,  4.7930e-01,  4.7918e-01, -5.1679e+00, -3.5489e+00],\n",
      "        [ 7.1007e-01,  1.4130e+00,  7.9493e-01,  6.3019e-01, -5.7603e-01,\n",
      "          1.1013e+00, -9.2203e-02,  1.2587e+00, -4.8116e+00, -3.3460e+00],\n",
      "        [ 2.7657e-01,  8.4019e-01,  9.8780e-01,  7.5924e-01,  1.8034e-01,\n",
      "          9.5411e-01,  1.7748e-01,  7.7765e-01, -4.9695e+00, -3.3979e+00],\n",
      "        [ 3.5081e+00, -1.2844e+00,  2.8402e+00,  1.1123e+00,  1.2070e+00,\n",
      "          3.2661e-01, -8.6604e-01,  1.3014e+00, -2.6103e+01, -1.3648e+01],\n",
      "        [ 2.0754e-01, -1.4543e-01,  1.0589e+00,  8.1731e-01,  1.4693e+00,\n",
      "          5.4901e-01,  6.1399e-01,  2.1746e-01, -5.4006e+00, -3.6815e+00],\n",
      "        [ 3.6092e-01,  6.1343e-02,  8.8008e-01,  7.9255e-01,  1.2735e+00,\n",
      "          5.1037e-01,  4.9961e-01,  2.8658e-01, -5.2816e+00, -3.6360e+00],\n",
      "        [ 6.3330e-01,  4.5166e-01,  6.9082e-01,  6.9189e-01,  7.5916e-01,\n",
      "          5.3074e-01,  3.0168e-01,  6.5859e-01, -5.1290e+00, -3.5492e+00],\n",
      "        [ 5.1911e-01,  2.5330e-01,  8.8327e-01,  6.6439e-01,  9.6727e-01,\n",
      "          6.0988e-01,  4.0523e-01,  4.4526e-01, -5.2303e+00, -3.6079e+00],\n",
      "        [ 2.3994e-01, -1.1320e-01,  1.1636e+00,  8.9509e-01,  1.4177e+00,\n",
      "          5.9155e-01,  5.5724e-01,  1.2907e-01, -5.6107e+00, -3.8175e+00],\n",
      "        [ 2.2277e-01, -5.7794e-01,  1.1341e+00,  7.5222e-01,  1.9963e+00,\n",
      "          4.6645e-01,  7.8209e-01, -8.4812e-02, -5.5715e+00, -3.8108e+00],\n",
      "        [ 5.6543e-01,  1.4088e+00,  8.5558e-01,  6.5613e-01, -5.6681e-01,\n",
      "          1.1160e+00, -5.8509e-02,  1.2396e+00, -4.7319e+00, -3.2831e+00],\n",
      "        [ 4.0930e-01,  1.3402e-01,  9.1807e-01,  7.3152e-01,  1.1242e+00,\n",
      "          5.9357e-01,  4.8162e-01,  3.7687e-01, -5.3076e+00, -3.6458e+00],\n",
      "        [ 3.6328e-01,  8.9854e-02,  8.9114e-01,  7.5871e-01,  1.1778e+00,\n",
      "          5.6138e-01,  4.8753e-01,  3.3191e-01, -5.2428e+00, -3.6110e+00]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>) is logits\n",
      "****************logits************\n",
      "\n",
      "<class 'torch.Tensor'> is logits's type\n",
      "***************logits's type*************\n",
      "\n",
      "torch.Size([32, 10]) is logits's shape\n",
      "***************logits's shape*************\n",
      "\n",
      "tensor([1.1648, 1.0514, 1.2385, 1.2768, 0.8080, 1.0847, 1.0458, 1.3022, 1.1925,\n",
      "        1.0400, 1.5721, 0.9037, 2.5879, 7.3644, 0.9254, 1.0535, 0.9238, 1.1053,\n",
      "        0.9086, 1.1900, 1.4130, 0.9878, 3.5081, 1.4693, 1.2735, 0.7592, 0.9673,\n",
      "        1.4177, 1.9963, 1.4088, 1.1242, 1.1778], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>) is _\n",
      "***************_*************\n",
      "\n",
      "tensor([1, 5, 1, 1, 2, 4, 5, 2, 7, 2, 1, 2, 4, 0, 1, 4, 2, 1, 2, 4, 1, 2, 0, 4,\n",
      "        4, 4, 4, 4, 4, 1, 4, 4], device='cuda:0') is predict\n",
      "**************predict**************\n",
      "\n",
      "tensor([2, 3, 2, 7, 5, 6, 6, 2, 5, 0, 1, 7, 7, 1, 3, 3, 7, 2, 4, 3, 6, 3, 6, 0,\n",
      "        3, 6, 0, 6, 4, 7, 5, 7], device='cuda:0') is batch[1]\n",
      "******************batch[1]****************\n",
      "\n",
      "<class 'torch.Tensor'> is batch[1]'s type\n",
      "****************batch[1]'s type******************\n",
      "\n",
      "torch.Size([32]) is batch[1].shape\n",
      "*****************batch[1].shape*****************\n",
      "\n",
      "tensor([[ 6.9325e-01,  1.3643e+00,  8.8820e-01,  7.3406e-01, -1.8543e-01,\n",
      "          9.7210e-01,  7.7123e-02,  1.1123e+00, -5.6280e+00, -3.9182e+00],\n",
      "        [ 4.2778e-01,  5.0001e-01,  1.4383e+00,  9.2962e-01,  6.6207e-01,\n",
      "          8.8361e-01,  4.4126e-01,  3.9281e-01, -6.3490e+00, -4.2693e+00],\n",
      "        [ 4.7890e-01,  9.7973e-01,  1.1301e+00,  8.2348e-01,  2.6869e-01,\n",
      "          9.6821e-01,  2.4528e-01,  8.0810e-01, -5.8349e+00, -4.0167e+00],\n",
      "        [ 3.3727e-01,  8.7043e-01,  1.2283e+00,  9.1580e-01,  3.8288e-01,\n",
      "          1.0393e+00,  2.6859e-01,  6.7482e-01, -5.8962e+00, -4.0457e+00],\n",
      "        [ 1.7049e+00, -1.3557e+00,  3.4743e+00,  1.0849e+00,  1.6108e+00,\n",
      "          2.7651e-01, -8.5535e-02,  1.2080e+00, -2.2147e+01, -1.1516e+01],\n",
      "        [ 3.5114e-01,  8.1691e-01,  1.1949e+00,  8.9720e-01,  4.6814e-01,\n",
      "          9.4216e-01,  2.9622e-01,  6.6973e-01, -5.8562e+00, -4.0116e+00],\n",
      "        [ 5.1009e-01, -2.2114e-01,  1.5283e+00,  9.6728e-01,  1.7167e+00,\n",
      "          5.6921e-01,  6.9581e-01, -1.4912e-01, -7.8297e+00, -5.0659e+00],\n",
      "        [ 4.7363e-01,  1.3474e+00,  1.1205e+00,  7.7929e-01, -3.0254e-01,\n",
      "          1.1592e+00,  1.1593e-01,  1.0685e+00, -5.5382e+00, -3.8201e+00],\n",
      "        [ 5.1106e-01,  8.3614e-01,  1.0705e+00,  9.0078e-01,  4.9574e-01,\n",
      "          8.1151e-01,  2.8024e-01,  7.4116e-01, -5.9849e+00, -4.1195e+00],\n",
      "        [ 1.5562e+00,  3.7386e-01,  2.2475e+00,  9.1879e-01,  1.4787e-01,\n",
      "          6.5271e-01, -3.4338e-01,  1.3328e+00, -1.5287e+01, -8.4660e+00],\n",
      "        [ 5.3764e-01,  1.5903e+00,  9.7828e-01,  7.7705e-01, -5.0645e-01,\n",
      "          1.1250e+00, -1.0499e-02,  1.2135e+00, -5.5277e+00, -3.8145e+00],\n",
      "        [ 3.9943e+00, -4.5444e+00,  5.8373e+00,  1.4598e+00,  4.6012e+00,\n",
      "         -1.0809e+00, -1.1240e+00,  2.3622e+00, -4.5862e+01, -2.3287e+01],\n",
      "        [ 7.5507e-01,  1.2423e+00,  9.5440e-01,  6.6500e-01, -3.7689e-02,\n",
      "          9.5669e-01,  9.9627e-02,  1.0207e+00, -5.6897e+00, -3.9584e+00],\n",
      "        [ 4.6421e-01,  1.2411e+00,  1.0579e+00,  8.1100e-01, -5.7412e-02,\n",
      "          1.0384e+00,  1.3316e-01,  9.4758e-01, -5.6767e+00, -3.9154e+00],\n",
      "        [ 2.6291e-01, -4.0704e-01,  1.5129e+00,  1.0216e+00,  2.3063e+00,\n",
      "          3.5793e-01,  8.0143e-01, -3.4855e-01, -6.8390e+00, -4.5843e+00],\n",
      "        [ 6.9255e-01,  1.0017e+00,  1.0041e+00,  7.3022e-01,  2.7314e-01,\n",
      "          9.2078e-01,  2.0324e-01,  8.1390e-01, -5.8449e+00, -4.0650e+00],\n",
      "        [ 5.8237e-01,  1.5720e+00,  1.0546e+00,  7.4235e-01, -5.5253e-01,\n",
      "          1.1800e+00, -1.1980e-03,  1.2468e+00, -5.5094e+00, -3.7987e+00],\n",
      "        [ 7.8787e-01,  8.6480e-01,  1.6060e+00,  9.6531e-01,  3.3984e-01,\n",
      "          8.0716e-01,  9.5058e-03,  6.4509e-01, -8.6103e+00, -5.4129e+00],\n",
      "        [ 6.3395e-01,  1.6061e+00,  9.2730e-01,  7.6237e-01, -4.6639e-01,\n",
      "          1.1109e+00, -2.6395e-02,  1.2454e+00, -5.6243e+00, -3.9108e+00],\n",
      "        [ 6.9108e-01,  1.3187e+00,  9.1341e-01,  7.7211e-01, -1.6665e-01,\n",
      "          9.7498e-01,  7.9629e-02,  1.1165e+00, -5.6572e+00, -3.9131e+00],\n",
      "        [ 9.4394e-01,  5.1877e-01,  1.8357e+00,  9.1664e-01,  2.8941e-01,\n",
      "          7.4810e-01,  9.4512e-02,  7.7677e-01, -1.0578e+01, -6.1371e+00],\n",
      "        [ 3.0260e-01,  1.0151e-01,  1.2210e+00,  9.0055e-01,  1.4559e+00,\n",
      "          6.9810e-01,  6.1967e-01,  1.7826e-01, -6.1975e+00, -4.2512e+00],\n",
      "        [ 6.0932e-01,  1.7546e+00,  1.0094e+00,  7.7984e-01, -7.2776e-01,\n",
      "          1.1507e+00, -7.2598e-02,  1.3986e+00, -5.5339e+00, -3.8230e+00],\n",
      "        [ 5.9427e-01,  2.6826e-01,  1.0699e+00,  7.0994e-01,  1.2847e+00,\n",
      "          5.8049e-01,  5.6247e-01,  3.8294e-01, -6.1392e+00, -4.2699e+00],\n",
      "        [ 2.7560e-01, -1.0554e-01,  1.2968e+00,  8.8558e-01,  1.7067e+00,\n",
      "          6.1815e-01,  7.1914e-01,  7.6034e-02, -6.2860e+00, -4.3158e+00],\n",
      "        [ 3.9666e-01, -9.1717e-01,  1.1678e+00,  8.1762e-01,  2.8194e+00,\n",
      "          1.9296e-01,  1.1062e+00, -2.7493e-01, -6.6616e+00, -4.5884e+00],\n",
      "        [ 8.3762e-01, -3.3722e-01,  1.8932e+00,  1.0280e+00,  1.6259e+00,\n",
      "          2.7586e-01,  4.8822e-01,  2.7676e-01, -1.1178e+01, -6.4968e+00],\n",
      "        [ 4.6607e-01, -6.3374e-01,  9.7258e-01,  8.6621e-01,  2.5137e+00,\n",
      "          1.0902e-01,  1.0134e+00, -4.3552e-02, -6.4583e+00, -4.4137e+00],\n",
      "        [ 5.7233e-01,  8.2739e-01,  9.0791e-01,  8.7801e-01,  6.1717e-01,\n",
      "          6.4314e-01,  3.3565e-01,  9.6773e-01, -6.0108e+00, -4.1353e+00],\n",
      "        [ 7.2886e-01,  1.4563e+00,  7.4623e-01,  7.3587e-01, -1.9853e-01,\n",
      "          8.9471e-01,  4.4064e-02,  1.1748e+00, -5.6476e+00, -3.9354e+00],\n",
      "        [ 6.4391e-01,  5.3953e-01,  9.9383e-01,  7.1380e-01,  9.4559e-01,\n",
      "          6.5028e-01,  4.4661e-01,  5.5997e-01, -6.0166e+00, -4.1869e+00],\n",
      "        [ 5.8902e-01,  1.1837e+00,  1.0998e+00,  7.6528e-01, -5.4580e-02,\n",
      "          1.1054e+00,  1.5178e-01,  9.6332e-01, -5.7357e+00, -3.9495e+00]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>) is logits\n",
      "****************logits************\n",
      "\n",
      "<class 'torch.Tensor'> is logits's type\n",
      "***************logits's type*************\n",
      "\n",
      "torch.Size([32, 10]) is logits's shape\n",
      "***************logits's shape*************\n",
      "\n",
      "tensor([1.3643, 1.4383, 1.1301, 1.2283, 3.4743, 1.1949, 1.7167, 1.3474, 1.0705,\n",
      "        2.2475, 1.5903, 5.8373, 1.2423, 1.2411, 2.3063, 1.0041, 1.5720, 1.6060,\n",
      "        1.6061, 1.3187, 1.8357, 1.4559, 1.7546, 1.2847, 1.7067, 2.8194, 1.8932,\n",
      "        2.5137, 0.9677, 1.4563, 0.9938, 1.1837], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>) is _\n",
      "***************_*************\n",
      "\n",
      "tensor([1, 2, 2, 2, 2, 2, 4, 1, 2, 2, 1, 2, 1, 1, 4, 2, 1, 2, 1, 1, 2, 4, 1, 4,\n",
      "        4, 4, 2, 4, 7, 1, 2, 1], device='cuda:0') is predict\n",
      "**************predict**************\n",
      "\n",
      "tensor([5, 3, 3, 7, 5, 1, 7, 4, 5, 7, 5, 6, 5, 5, 5, 1, 3, 4, 2, 5, 4, 6, 5, 2,\n",
      "        0, 0, 2, 2, 5, 3, 7, 0], device='cuda:0') is batch[1]\n",
      "******************batch[1]****************\n",
      "\n",
      "<class 'torch.Tensor'> is batch[1]'s type\n",
      "****************batch[1]'s type******************\n",
      "\n",
      "torch.Size([32]) is batch[1].shape\n",
      "*****************batch[1].shape*****************\n",
      "\n",
      "tensor([[ 2.7158e-01,  1.2807e+00,  1.4211e+00,  9.0487e-01, -2.6631e-01,\n",
      "          1.1953e+00,  1.4937e-01,  8.7909e-01, -5.7694e+00, -3.9468e+00],\n",
      "        [ 3.9110e-01,  1.0293e+00,  1.2240e+00,  9.1958e-01,  1.8699e-01,\n",
      "          9.8710e-01,  2.8400e-01,  7.6093e-01, -5.9766e+00, -4.0959e+00],\n",
      "        [ 4.4132e-01,  6.6527e-01,  1.1942e+00,  9.3547e-01,  6.3718e-01,\n",
      "          8.5158e-01,  4.7225e-01,  5.3466e-01, -6.1632e+00, -4.2366e+00],\n",
      "        [ 4.1538e-01, -2.9638e-01,  1.0618e+00,  1.1045e+00,  1.9397e+00,\n",
      "          2.3832e-01,  9.4419e-01,  1.0529e-01, -6.4861e+00, -4.4240e+00],\n",
      "        [ 4.6645e-01,  1.0639e+00,  1.1582e+00,  9.3616e-01,  1.4313e-01,\n",
      "          1.0002e+00,  2.8323e-01,  7.8986e-01, -5.9985e+00, -4.1309e+00],\n",
      "        [ 3.5575e-01,  1.0223e+00,  1.2890e+00,  9.6722e-01,  1.6899e-01,\n",
      "          1.0431e+00,  2.8031e-01,  7.3220e-01, -5.9965e+00, -4.1109e+00],\n",
      "        [ 3.9275e-01,  1.2089e+00,  1.1754e+00,  9.3880e-01, -4.5042e-02,\n",
      "          1.0472e+00,  2.0200e-01,  8.8755e-01, -5.8590e+00, -4.0084e+00],\n",
      "        [ 1.5479e+00, -1.5325e+00,  3.6436e+00,  9.7738e-01,  2.1522e+00,\n",
      "         -2.7024e-01,  1.9243e-01,  9.9901e-01, -2.3787e+01, -1.2674e+01],\n",
      "        [ 7.7630e-01,  1.9073e+00,  9.7624e-01,  7.4443e-01, -8.9546e-01,\n",
      "          1.1678e+00, -1.3262e-01,  1.4664e+00, -5.6703e+00, -3.9476e+00],\n",
      "        [ 4.5378e-01,  8.1018e-01,  1.2465e+00,  9.0906e-01,  4.1967e-01,\n",
      "          9.6498e-01,  4.0471e-01,  6.5242e-01, -6.0756e+00, -4.1723e+00],\n",
      "        [ 4.4212e-01,  1.5795e+00,  1.2553e+00,  8.7246e-01, -5.7007e-01,\n",
      "          1.2100e+00,  1.1691e-02,  1.1457e+00, -5.7341e+00, -3.9323e+00],\n",
      "        [ 3.7874e-01, -6.4854e-01,  1.0075e+00,  9.9746e-01,  2.5141e+00,\n",
      "          1.2348e-01,  1.2307e+00, -2.3253e-01, -6.6906e+00, -4.5939e+00],\n",
      "        [ 4.6992e-01,  8.6551e-01,  1.0901e+00,  9.1582e-01,  4.4268e-01,\n",
      "          8.1724e-01,  3.8492e-01,  6.9566e-01, -6.0328e+00, -4.1617e+00],\n",
      "        [ 3.4906e-01,  1.2585e+00,  1.3250e+00,  9.1401e-01, -2.3907e-01,\n",
      "          1.0962e+00,  1.5031e-01,  9.6261e-01, -5.7574e+00, -3.9355e+00],\n",
      "        [ 3.1516e-01,  1.2430e+00,  1.3356e+00,  9.4774e-01, -1.6129e-01,\n",
      "          1.1490e+00,  1.6380e-01,  8.6039e-01, -5.8528e+00, -4.0168e+00],\n",
      "        [ 6.9335e-01,  6.1911e-01,  1.0708e+00,  8.3155e-01,  7.9376e-01,\n",
      "          6.9113e-01,  5.0617e-01,  5.1681e-01, -6.2144e+00, -4.3140e+00],\n",
      "        [ 3.1161e-01,  5.7998e-01,  1.2406e+00,  9.9952e-01,  7.5624e-01,\n",
      "          8.0201e-01,  5.2623e-01,  4.7346e-01, -6.1174e+00, -4.1858e+00],\n",
      "        [ 3.6738e+00, -3.5787e+00,  6.8957e+00,  1.0677e+00,  3.1545e+00,\n",
      "         -1.4873e+00, -1.2997e+00,  4.5415e+00, -5.4226e+01, -2.7390e+01],\n",
      "        [ 6.7245e-01, -2.0146e-01,  2.1072e+00,  1.0699e+00,  1.3821e+00,\n",
      "          3.4133e-01,  6.3004e-01,  2.9323e-01, -1.1517e+01, -6.7776e+00],\n",
      "        [ 5.9348e-01,  4.0258e-01,  9.7037e-01,  1.0289e+00,  1.1585e+00,\n",
      "          3.3241e-01,  5.7266e-01,  5.9149e-01, -6.2935e+00, -4.3186e+00],\n",
      "        [ 3.8388e-01, -7.8943e-01,  1.1584e+00,  1.0020e+00,  2.5012e+00,\n",
      "          2.8362e-01,  1.2093e+00, -3.1046e-01, -6.7758e+00, -4.6161e+00],\n",
      "        [ 1.6001e+00, -6.6701e-01,  3.1014e+00,  1.0656e+00,  1.4542e+00,\n",
      "         -3.2557e-01,  2.9201e-02,  1.5851e+00, -2.1852e+01, -1.1795e+01],\n",
      "        [ 8.5092e-01,  1.3652e+00,  1.0102e+00,  7.1284e-01, -2.0876e-01,\n",
      "          9.6797e-01,  9.5284e-02,  1.0617e+00, -5.8500e+00, -4.0706e+00],\n",
      "        [ 4.6592e-01,  7.5690e-01,  1.0634e+00,  9.7346e-01,  5.7600e-01,\n",
      "          8.2618e-01,  4.0978e-01,  6.4011e-01, -6.0953e+00, -4.1814e+00],\n",
      "        [ 6.6785e-01,  1.3318e+00,  9.8627e-01,  8.1256e-01, -1.2030e-01,\n",
      "          9.5420e-01,  1.6876e-01,  1.0177e+00, -5.9090e+00, -4.1123e+00],\n",
      "        [ 5.4050e-01,  1.0772e+00,  1.0484e+00,  8.8984e-01,  2.2045e-01,\n",
      "          9.0419e-01,  2.8025e-01,  8.2536e-01, -6.0436e+00, -4.1847e+00],\n",
      "        [ 6.5162e-01,  1.4873e+00,  1.0821e+00,  8.5554e-01, -3.7104e-01,\n",
      "          1.1048e+00,  3.5766e-02,  1.1229e+00, -5.8766e+00, -4.0617e+00],\n",
      "        [ 3.0318e-01,  5.5878e-02,  1.2474e+00,  1.0225e+00,  1.4646e+00,\n",
      "          6.2578e-01,  7.9479e-01,  5.6874e-02, -6.3960e+00, -4.3939e+00],\n",
      "        [ 9.4431e-01,  1.4828e+00,  8.7446e-01,  6.9148e-01, -3.1753e-01,\n",
      "          9.3534e-01,  6.4910e-02,  1.1351e+00, -5.7937e+00, -4.0332e+00],\n",
      "        [ 4.9226e-01, -4.5573e-01,  9.8051e-01,  1.0058e+00,  2.1815e+00,\n",
      "          2.0201e-01,  1.0818e+00, -7.4877e-02, -6.6026e+00, -4.5180e+00],\n",
      "        [ 5.5451e-01,  1.1923e+00,  1.1005e+00,  8.9817e-01,  3.9773e-04,\n",
      "          1.0068e+00,  2.0904e-01,  9.2103e-01, -5.9932e+00, -4.1411e+00],\n",
      "        [ 4.2485e-01,  9.4995e-01,  1.1855e+00,  9.5238e-01,  3.0013e-01,\n",
      "          9.3790e-01,  3.3385e-01,  7.1807e-01, -6.0230e+00, -4.1491e+00]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>) is logits\n",
      "****************logits************\n",
      "\n",
      "<class 'torch.Tensor'> is logits's type\n",
      "***************logits's type*************\n",
      "\n",
      "torch.Size([32, 10]) is logits's shape\n",
      "***************logits's shape*************\n",
      "\n",
      "tensor([1.4211, 1.2240, 1.1942, 1.9397, 1.1582, 1.2890, 1.2089, 3.6436, 1.9073,\n",
      "        1.2465, 1.5795, 2.5141, 1.0901, 1.3250, 1.3356, 1.0708, 1.2406, 6.8957,\n",
      "        2.1072, 1.1585, 2.5012, 3.1014, 1.3652, 1.0634, 1.3318, 1.0772, 1.4873,\n",
      "        1.4646, 1.4828, 2.1815, 1.1923, 1.1855], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>) is _\n",
      "***************_*************\n",
      "\n",
      "tensor([2, 2, 2, 4, 2, 2, 1, 2, 1, 2, 1, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 1, 2,\n",
      "        1, 1, 1, 4, 1, 4, 1, 2], device='cuda:0') is predict\n",
      "**************predict**************\n",
      "\n",
      "tensor([6, 2, 7, 1, 6, 1, 5, 7, 4, 1, 1, 7, 5, 7, 5, 6, 1, 2, 0, 1, 1, 5, 4, 0,\n",
      "        5, 6, 5, 7, 5, 5, 7, 1], device='cuda:0') is batch[1]\n",
      "******************batch[1]****************\n",
      "\n",
      "<class 'torch.Tensor'> is batch[1]'s type\n",
      "****************batch[1]'s type******************\n",
      "\n",
      "torch.Size([32]) is batch[1].shape\n",
      "*****************batch[1].shape*****************\n",
      "\n",
      "tensor([[ 2.7197e-01, -9.2375e-02,  1.1982e+00,  1.0767e+00,  1.4801e+00,\n",
      "          6.0527e-01,  9.5912e-01,  3.1777e-02, -6.2760e+00, -4.2741e+00],\n",
      "        [ 2.6484e-02, -1.2803e+00,  1.2002e+00,  1.1830e+00,  3.0538e+00,\n",
      "          7.1906e-02,  1.6924e+00, -6.4820e-01, -6.7853e+00, -4.6139e+00],\n",
      "        [ 3.3074e-01,  7.6386e-01,  1.1336e+00,  9.2858e-01,  4.1060e-01,\n",
      "          8.6735e-01,  4.5948e-01,  5.8822e-01, -5.8192e+00, -3.9811e+00],\n",
      "        [ 4.7646e-01,  1.2153e+00,  1.1337e+00,  8.2554e-01, -2.5768e-01,\n",
      "          1.1158e+00,  1.9979e-01,  9.7676e-01, -5.6039e+00, -3.8384e+00],\n",
      "        [ 6.6620e-01,  3.5163e-01,  6.9948e-01,  9.3629e-01,  1.0847e+00,\n",
      "          3.7874e-01,  7.5000e-01,  4.6195e-01, -6.0486e+00, -4.1636e+00],\n",
      "        [ 4.2793e-01,  1.5794e+00,  1.2458e+00,  7.0602e-01, -8.9612e-01,\n",
      "          1.3278e+00, -4.0806e-03,  1.2730e+00, -5.2222e+00, -3.5778e+00],\n",
      "        [ 3.9305e-01, -1.4878e-01,  9.8240e-01,  1.1423e+00,  1.8272e+00,\n",
      "          7.6828e-02,  1.0898e+00,  1.2577e-01, -6.7282e+00, -4.5542e+00],\n",
      "        [ 4.1247e-01,  6.9171e-01,  1.0678e+00,  9.2581e-01,  5.6326e-01,\n",
      "          8.1764e-01,  5.3198e-01,  5.6872e-01, -5.9845e+00, -4.1160e+00],\n",
      "        [ 3.7608e-01,  1.2656e+00,  1.1226e+00,  8.7732e-01, -2.4990e-01,\n",
      "          1.1289e+00,  1.7529e-01,  9.5183e-01, -5.6267e+00, -3.8583e+00],\n",
      "        [ 1.7339e+00, -4.7188e+00,  5.7059e+00,  7.9994e-01,  5.1381e+00,\n",
      "         -1.8723e+00,  6.1470e-01,  6.0938e+00, -5.7755e+01, -2.8925e+01],\n",
      "        [ 4.3473e-01,  1.1760e+00,  1.1314e+00,  8.5703e-01, -1.3714e-01,\n",
      "          1.0990e+00,  2.0691e-01,  9.1866e-01, -5.7223e+00, -3.9384e+00],\n",
      "        [ 4.0784e-01,  1.0512e+00,  1.0805e+00,  9.3399e-01,  8.2440e-02,\n",
      "          9.9873e-01,  2.8721e-01,  8.3476e-01, -5.8102e+00, -3.9973e+00],\n",
      "        [ 1.8821e-01, -6.0642e-01,  1.1485e+00,  1.0947e+00,  2.1478e+00,\n",
      "          3.6696e-01,  1.3004e+00, -2.6978e-01, -6.4827e+00, -4.4172e+00],\n",
      "        [ 6.7342e-01,  1.2571e+00,  1.2169e+00,  8.7292e-01,  3.0566e-02,\n",
      "          8.7609e-01,  2.0107e-01,  9.6303e-01, -6.9051e+00, -4.6150e+00],\n",
      "        [-3.6154e-01,  1.0245e+00,  2.1271e+00,  1.2297e+00,  2.7883e+00,\n",
      "          2.0404e-02, -7.7154e-02, -1.4791e+00, -1.5297e+01, -8.3100e+00],\n",
      "        [ 1.8787e-01, -1.1665e+00,  8.8327e-01,  1.1661e+00,  3.0562e+00,\n",
      "         -1.7864e-01,  1.7573e+00, -5.1580e-01, -6.6963e+00, -4.5873e+00],\n",
      "        [ 5.1058e-01,  1.9484e-01,  1.1362e+00,  1.1351e+00,  1.3767e+00,\n",
      "          3.5977e-01,  7.5366e-01,  2.1491e-01, -6.9302e+00, -4.6653e+00],\n",
      "        [ 8.9164e-01,  1.9658e+00,  7.9342e-01,  5.9237e-01, -1.0316e+00,\n",
      "          1.1901e+00, -1.8468e-01,  1.5754e+00, -5.3650e+00, -3.7440e+00],\n",
      "        [ 4.6360e-01,  1.5768e+00,  1.1927e+00,  7.8131e-01, -7.0897e-01,\n",
      "          1.3055e+00,  6.2510e-03,  1.2196e+00, -5.4976e+00, -3.7713e+00],\n",
      "        [ 7.0411e-01,  4.2629e-01,  9.0085e-01,  8.2996e-01,  9.0663e-01,\n",
      "          5.9687e-01,  6.7156e-01,  4.1785e-01, -6.0517e+00, -4.1891e+00],\n",
      "        [ 5.9794e-01,  1.3125e+00,  1.1537e+00,  8.4978e-01, -1.1310e-01,\n",
      "          8.4359e-01,  1.8257e-01,  1.1831e+00, -6.0031e+00, -4.1578e+00],\n",
      "        [ 2.9142e-01,  6.3691e-01,  1.4461e+00,  9.7350e-01,  4.4029e-01,\n",
      "          8.6887e-01,  5.8229e-01,  3.9783e-01, -6.6779e+00, -4.3849e+00],\n",
      "        [ 3.5928e-01, -7.6641e-01,  1.0170e+00,  1.0411e+00,  2.3561e+00,\n",
      "          1.9912e-01,  1.3969e+00, -2.8564e-01, -6.5448e+00, -4.4672e+00],\n",
      "        [ 7.7986e-01,  9.7648e-02,  1.5109e+00,  8.1445e-01,  9.0575e-01,\n",
      "          3.9966e-01,  6.7964e-01,  7.4580e-01, -1.1045e+01, -6.4457e+00],\n",
      "        [ 6.9513e-01,  1.2570e+00,  9.5958e-01,  7.5991e-01, -1.8881e-01,\n",
      "          1.0209e+00,  2.0235e-01,  1.0418e+00, -5.7285e+00, -3.9647e+00],\n",
      "        [ 3.7494e-01,  1.2115e+00,  1.1540e+00,  9.1152e-01, -1.7227e-01,\n",
      "          1.1379e+00,  1.6869e-01,  8.8517e-01, -5.6721e+00, -3.9198e+00],\n",
      "        [ 4.2995e-01,  6.0381e-01,  1.1775e+00,  9.2714e-01,  5.3872e-01,\n",
      "          9.4652e-01,  5.2575e-01,  5.0138e-01, -5.9847e+00, -4.0971e+00],\n",
      "        [ 2.5099e-01,  8.6124e-01,  1.2446e+00,  1.0037e+00,  2.4368e-01,\n",
      "          1.0390e+00,  3.6010e-01,  6.2107e-01, -5.8316e+00, -4.0067e+00],\n",
      "        [ 6.8595e-01,  1.6195e+00,  1.0567e+00,  7.0971e-01, -7.4806e-01,\n",
      "          1.2637e+00, -1.8382e-02,  1.3149e+00, -5.5100e+00, -3.8050e+00],\n",
      "        [ 7.4961e-01,  1.0447e+00,  1.7188e+00,  8.5132e-01,  2.0500e-02,\n",
      "          6.4923e-01, -4.2059e-02,  1.4710e+00, -1.1563e+01, -6.7871e+00],\n",
      "        [ 4.3111e-01,  1.4040e+00,  1.1822e+00,  8.2121e-01, -4.9042e-01,\n",
      "          1.2152e+00,  1.3590e-01,  1.0855e+00, -5.5580e+00, -3.8082e+00],\n",
      "        [ 7.1209e-01,  1.3271e+00,  1.1809e+00,  8.5882e-01, -1.7634e-02,\n",
      "          7.7413e-01,  1.0872e-01,  1.0756e+00, -7.4973e+00, -4.9023e+00]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>) is logits\n",
      "****************logits************\n",
      "\n",
      "<class 'torch.Tensor'> is logits's type\n",
      "***************logits's type*************\n",
      "\n",
      "torch.Size([32, 10]) is logits's shape\n",
      "***************logits's shape*************\n",
      "\n",
      "tensor([1.4801, 3.0538, 1.1336, 1.2153, 1.0847, 1.5794, 1.8272, 1.0678, 1.2656,\n",
      "        6.0938, 1.1760, 1.0805, 2.1478, 1.2571, 2.7883, 3.0562, 1.3767, 1.9658,\n",
      "        1.5768, 0.9066, 1.3125, 1.4461, 2.3561, 1.5109, 1.2570, 1.2115, 1.1775,\n",
      "        1.2446, 1.6195, 1.7188, 1.4040, 1.3271], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>) is _\n",
      "***************_*************\n",
      "\n",
      "tensor([4, 4, 2, 1, 4, 1, 4, 2, 1, 7, 1, 2, 4, 1, 4, 4, 4, 1, 1, 4, 1, 2, 4, 2,\n",
      "        1, 1, 2, 2, 1, 2, 1, 1], device='cuda:0') is predict\n",
      "**************predict**************\n",
      "\n",
      "tensor([1, 1, 3, 2, 6, 5, 7, 6, 1, 4, 6, 1, 7, 5, 2, 3, 0, 4, 4, 7, 3, 5, 5, 4,\n",
      "        3, 2, 4, 7, 5, 6, 4, 6], device='cuda:0') is batch[1]\n",
      "******************batch[1]****************\n",
      "\n",
      "<class 'torch.Tensor'> is batch[1]'s type\n",
      "****************batch[1]'s type******************\n",
      "\n",
      "torch.Size([32]) is batch[1].shape\n",
      "*****************batch[1].shape*****************\n",
      "\n",
      "tensor([[ 5.5061e-01,  9.4896e-01,  8.1226e-01,  7.7581e-01,  1.5365e-01,\n",
      "          8.8702e-01,  4.0806e-01,  7.4363e-01, -5.4690e+00, -3.8137e+00],\n",
      "        [ 6.7560e-01,  9.8660e-01,  7.3003e-01,  7.4421e-01,  1.1276e-01,\n",
      "          7.9095e-01,  4.1167e-01,  6.8955e-01, -5.6691e+00, -3.8820e+00],\n",
      "        [ 1.6287e-01,  5.8113e-01,  1.1367e+00,  9.5325e-01,  4.5733e-01,\n",
      "          9.5654e-01,  5.8119e-01,  3.8843e-01, -5.5405e+00, -3.7984e+00],\n",
      "        [ 4.1904e-01,  8.9361e-02,  7.9554e-01,  9.0680e-01,  1.1414e+00,\n",
      "          5.7149e-01,  9.9437e-01,  9.7329e-02, -5.6993e+00, -3.9434e+00],\n",
      "        [ 5.0306e-01,  1.0785e+00,  9.7777e-01,  8.0374e-01,  6.6514e-02,\n",
      "          9.3766e-01,  3.6325e-01,  6.7716e-01, -5.7751e+00, -3.9418e+00],\n",
      "        [ 2.1903e-01,  1.3312e-01,  9.6750e-01,  1.0148e+00,  1.0801e+00,\n",
      "          6.4807e-01,  9.2637e-01,  1.2129e-01, -5.7438e+00, -3.9377e+00],\n",
      "        [ 1.9087e-01,  7.0460e-01,  1.2337e+00,  8.5546e-01,  2.4606e-01,\n",
      "          1.0760e+00,  5.1736e-01,  5.0279e-01, -5.4710e+00, -3.7362e+00],\n",
      "        [ 6.5208e-01,  9.6066e-01,  6.7988e-01,  7.4045e-01,  1.8133e-01,\n",
      "          8.0295e-01,  3.9210e-01,  7.7760e-01, -5.3861e+00, -3.7480e+00],\n",
      "        [ 2.0209e-01, -3.8659e-01,  9.7519e-01,  1.0197e+00,  1.6656e+00,\n",
      "          4.7181e-01,  1.3113e+00, -2.0070e-01, -5.9551e+00, -4.0902e+00],\n",
      "        [ 4.9585e-01,  2.9982e-01,  6.7942e-01,  8.8353e-01,  1.0004e+00,\n",
      "          4.7438e-01,  8.9949e-01,  2.5880e-01, -5.6669e+00, -3.9229e+00],\n",
      "        [ 6.7300e-01,  1.7045e+00,  8.8958e-01,  5.9589e-01, -7.9142e-01,\n",
      "          1.2965e+00, -1.2111e-01,  1.3218e+00, -5.2012e+00, -3.6237e+00],\n",
      "        [ 4.1744e-01,  1.3005e+00,  1.0602e+00,  7.8522e-01, -3.9504e-01,\n",
      "          1.2312e+00,  1.2331e-01,  9.3013e-01, -5.2591e+00, -3.6060e+00],\n",
      "        [ 5.1297e-01,  1.1019e+00,  1.2813e+00,  7.6417e-01,  3.6869e-01,\n",
      "          7.3157e-01,  2.4628e-01,  1.1981e+00, -1.1605e+01, -6.8011e+00],\n",
      "        [ 3.8014e-01,  1.1304e-01,  1.2650e+00,  9.8225e-01,  1.7277e+00,\n",
      "          1.0844e-01,  8.0789e-01,  9.9424e-01, -1.5299e+01, -8.6524e+00],\n",
      "        [ 2.5555e-01,  1.4136e+00,  1.3149e+00,  6.5076e-01, -7.5690e-01,\n",
      "          1.3992e+00,  3.1114e-02,  1.0664e+00, -4.9666e+00, -3.3838e+00],\n",
      "        [ 2.5077e-01,  1.1052e+00,  1.0632e+00,  8.2956e-01, -1.1000e-01,\n",
      "          1.1059e+00,  2.2449e-01,  7.8820e-01, -5.2849e+00, -3.6176e+00],\n",
      "        [ 6.5685e-01,  1.3731e+00,  8.0417e-01,  7.3113e-01, -2.5040e-01,\n",
      "          1.0167e+00,  1.0901e-01,  1.0816e+00, -5.4497e+00, -3.8146e+00],\n",
      "        [ 2.7769e-01,  1.2146e+00,  1.2554e+00,  7.6267e-01, -4.0709e-01,\n",
      "          1.3122e+00,  1.5103e-01,  9.1080e-01, -5.2057e+00, -3.5621e+00],\n",
      "        [ 3.3011e-01,  1.1397e-01,  8.9298e-01,  9.4713e-01,  1.1164e+00,\n",
      "          6.1989e-01,  9.5776e-01,  1.4234e-01, -5.7857e+00, -3.9992e+00],\n",
      "        [ 2.3722e-01,  9.2717e-01,  1.1652e+00,  8.4553e-01,  4.9837e-03,\n",
      "          1.1261e+00,  3.4589e-01,  6.5461e-01, -5.3613e+00, -3.6682e+00],\n",
      "        [ 5.5731e-01,  6.4378e-01,  1.0860e+00,  8.4939e-01,  9.7181e-01,\n",
      "          4.1658e-01,  5.2668e-01,  9.3306e-01, -1.2221e+01, -7.1293e+00],\n",
      "        [ 4.7901e-01,  8.9769e-01,  8.0289e-01,  8.5707e-01,  2.4012e-01,\n",
      "          8.8629e-01,  4.1508e-01,  6.6635e-01, -5.4703e+00, -3.7979e+00],\n",
      "        [ 5.6960e-01,  9.9048e-01,  9.4567e-01,  7.9395e-01,  1.2742e-01,\n",
      "          9.0761e-01,  4.3879e-01,  6.2566e-01, -5.8177e+00, -3.9688e+00],\n",
      "        [ 7.8156e-01, -1.8859e+00,  2.7444e+00, -4.2434e-02,  5.9448e+00,\n",
      "         -1.7044e+00,  1.1553e+00,  6.2360e+00, -5.9684e+01, -3.0205e+01],\n",
      "        [ 5.5833e-01,  9.9087e-01,  8.9811e-01,  7.6218e-01,  5.5939e-02,\n",
      "          9.8014e-01,  3.5830e-01,  7.2176e-01, -5.4332e+00, -3.7786e+00],\n",
      "        [ 3.9388e-01,  5.8488e-01,  8.5862e-01,  8.9624e-01,  5.9845e-01,\n",
      "          7.6449e-01,  6.4559e-01,  4.3895e-01, -5.5880e+00, -3.8710e+00],\n",
      "        [ 5.6209e-01,  9.1196e-01,  7.7834e-01,  7.6151e-01,  2.0347e-01,\n",
      "          8.8919e-01,  4.3498e-01,  7.3136e-01, -5.4790e+00, -3.8097e+00],\n",
      "        [ 3.3148e-01,  1.3179e+00,  1.1508e+00,  7.3441e-01, -5.0675e-01,\n",
      "          1.2534e+00,  1.1954e-01,  9.8105e-01, -5.1036e+00, -3.4956e+00],\n",
      "        [ 2.9602e-01,  9.0455e-01,  1.0339e+00,  8.7906e-01,  1.0326e-01,\n",
      "          1.0600e+00,  3.5038e-01,  6.2304e-01, -5.4286e+00, -3.7447e+00],\n",
      "        [ 1.9786e-01, -2.7437e-01,  1.0082e+00,  1.0447e+00,  1.5076e+00,\n",
      "          5.5528e-01,  1.2087e+00, -1.2047e-01, -5.9187e+00, -4.0633e+00],\n",
      "        [ 1.2538e-01, -8.3045e-01,  7.7503e-01,  1.0581e+00,  2.3324e+00,\n",
      "          6.6083e-02,  1.7734e+00, -4.2178e-01, -6.1245e+00, -4.2153e+00],\n",
      "        [ 9.8432e-02,  3.4391e-01,  1.1609e+00,  9.9182e-01,  7.4623e-01,\n",
      "          8.5609e-01,  7.6943e-01,  2.3240e-01, -5.6553e+00, -3.8651e+00]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>) is logits\n",
      "****************logits************\n",
      "\n",
      "<class 'torch.Tensor'> is logits's type\n",
      "***************logits's type*************\n",
      "\n",
      "torch.Size([32, 10]) is logits's shape\n",
      "***************logits's shape*************\n",
      "\n",
      "tensor([0.9490, 0.9866, 1.1367, 1.1414, 1.0785, 1.0801, 1.2337, 0.9607, 1.6656,\n",
      "        1.0004, 1.7045, 1.3005, 1.2813, 1.7277, 1.4136, 1.1059, 1.3731, 1.3122,\n",
      "        1.1164, 1.1652, 1.0860, 0.8977, 0.9905, 6.2360, 0.9909, 0.8962, 0.9120,\n",
      "        1.3179, 1.0600, 1.5076, 2.3324, 1.1609], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>) is _\n",
      "***************_*************\n",
      "\n",
      "tensor([1, 1, 2, 4, 1, 4, 2, 1, 4, 4, 1, 1, 2, 4, 1, 5, 1, 5, 4, 2, 2, 1, 1, 7,\n",
      "        1, 3, 1, 1, 5, 4, 4, 2], device='cuda:0') is predict\n",
      "**************predict**************\n",
      "\n",
      "tensor([2, 2, 6, 2, 1, 3, 4, 5, 4, 2, 6, 5, 2, 0, 5, 0, 3, 0, 2, 5, 2, 3, 1, 7,\n",
      "        1, 0, 0, 3, 2, 0, 4, 3], device='cuda:0') is batch[1]\n",
      "******************batch[1]****************\n",
      "\n",
      "<class 'torch.Tensor'> is batch[1]'s type\n",
      "****************batch[1]'s type******************\n",
      "\n",
      "torch.Size([32]) is batch[1].shape\n",
      "*****************batch[1].shape*****************\n",
      "\n",
      "tensor([[ 2.1905e-01,  7.4952e-01,  1.0730e+00,  1.0364e+00,  4.4850e-01,\n",
      "          1.0935e+00,  7.5117e-01,  4.7928e-01, -6.2511e+00, -4.2859e+00],\n",
      "        [ 7.3072e-02,  3.8050e-01,  1.1543e+00,  1.1247e+00,  8.4858e-01,\n",
      "          9.6512e-01,  1.0185e+00,  1.9601e-01, -6.3594e+00, -4.3538e+00],\n",
      "        [ 3.9580e-01,  3.6848e-01,  5.4962e-01,  1.1079e+00,  1.0286e+00,\n",
      "          5.5708e-01,  1.1249e+00,  3.7663e-01, -6.2150e+00, -4.2655e+00],\n",
      "        [ 6.0391e-01,  1.5088e+00,  9.9542e-01,  7.9483e-01, -4.6284e-01,\n",
      "          1.4155e+00,  1.9381e-01,  1.1322e+00, -6.0473e+00, -4.1718e+00],\n",
      "        [ 4.3295e-01,  8.4572e-01,  8.4487e-01,  8.9575e-01,  4.3959e-01,\n",
      "          9.5584e-01,  7.5261e-01,  5.8504e-01, -6.1890e+00, -4.2828e+00],\n",
      "        [ 1.9181e-01,  8.4282e-01,  1.1630e+00,  1.0592e+00,  1.0452e+00,\n",
      "          8.5627e-01,  9.8526e-01,  2.4996e-01, -9.7108e+00, -6.0469e+00],\n",
      "        [ 1.5347e-01,  7.4616e-01,  1.0991e+00,  1.0496e+00,  4.4468e-01,\n",
      "          1.0545e+00,  7.2615e-01,  4.3823e-01, -6.1688e+00, -4.2094e+00],\n",
      "        [ 6.3822e-01,  1.5385e+00,  8.5584e-01,  7.4634e-01, -3.8066e-01,\n",
      "          1.3076e+00,  1.8266e-01,  1.1445e+00, -6.0217e+00, -4.1747e+00],\n",
      "        [ 7.2418e-02, -4.2813e-01,  8.7619e-01,  1.1617e+00,  1.8543e+00,\n",
      "          4.9380e-01,  1.7649e+00, -2.8421e-01, -6.6817e+00, -4.5872e+00],\n",
      "        [-1.3129e-02, -4.7130e-01,  9.6654e-01,  1.1921e+00,  1.9674e+00,\n",
      "          4.1830e-01,  1.8487e+00, -3.5577e-01, -6.7241e+00, -4.6197e+00],\n",
      "        [ 4.3205e-01,  4.3840e-01,  8.8428e-01,  9.3442e-01,  8.8616e-01,\n",
      "          7.8065e-01,  1.1206e+00,  2.6021e-01, -6.3855e+00, -4.4200e+00],\n",
      "        [ 1.5757e-01,  8.7631e-01,  1.2613e+00,  1.0196e+00,  1.9130e-01,\n",
      "          1.2706e+00,  6.4342e-01,  6.0118e-01, -6.2029e+00, -4.2342e+00],\n",
      "        [-2.3933e-02, -5.7450e-01,  9.4869e-01,  1.1930e+00,  2.0671e+00,\n",
      "          4.2186e-01,  1.9168e+00, -4.1229e-01, -6.7836e+00, -4.6552e+00],\n",
      "        [ 1.0435e-01,  7.8084e-01,  1.2699e+00,  1.0239e+00,  2.9704e-01,\n",
      "          1.2445e+00,  6.7343e-01,  4.8811e-01, -6.2005e+00, -4.2261e+00],\n",
      "        [ 3.9221e-01,  1.0615e+00,  9.0827e-01,  9.6010e-01,  1.4749e-01,\n",
      "          1.1113e+00,  5.3424e-01,  7.3396e-01, -6.0983e+00, -4.2132e+00],\n",
      "        [ 9.9007e-02,  6.3820e-01,  1.2157e+00,  1.0524e+00,  5.1219e-01,\n",
      "          1.1237e+00,  7.9888e-01,  3.8377e-01, -6.2521e+00, -4.2810e+00],\n",
      "        [ 5.2404e-01,  1.3318e+00,  1.0646e+00,  8.2205e-01, -3.1201e-01,\n",
      "          1.3879e+00,  3.0410e-01,  1.0103e+00, -6.0958e+00, -4.1836e+00],\n",
      "        [ 7.3943e-01,  1.2353e+00,  9.2485e-01,  7.3768e-01, -1.1635e-01,\n",
      "          1.1823e+00,  3.9688e-01,  8.9218e-01, -6.1181e+00, -4.2386e+00],\n",
      "        [ 6.2777e-01,  1.1655e+00,  8.2503e-01,  8.0102e-01,  2.7675e-02,\n",
      "          1.1191e+00,  4.8681e-01,  8.4797e-01, -6.1127e+00, -4.2304e+00],\n",
      "        [ 4.0420e-01,  1.5693e+00,  1.1505e+00,  8.2277e-01, -5.5920e-01,\n",
      "          1.4571e+00,  1.5630e-01,  1.2249e+00, -5.9565e+00, -4.0756e+00],\n",
      "        [ 4.7437e-01,  7.8546e-01,  8.5574e-01,  9.1837e-01,  4.9026e-01,\n",
      "          9.4365e-01,  7.8686e-01,  5.3542e-01, -6.2608e+00, -4.3220e+00],\n",
      "        [ 5.2393e-02,  9.3557e-01,  1.3640e+00,  9.8708e-01,  8.1229e-02,\n",
      "          1.3258e+00,  5.4641e-01,  6.1224e-01, -6.1153e+00, -4.1611e+00],\n",
      "        [ 2.5085e-01,  1.1970e+00,  1.1135e+00,  7.8650e-01,  7.5801e-01,\n",
      "          1.0053e+00,  6.7099e-01,  8.4627e-01, -1.2827e+01, -7.4780e+00],\n",
      "        [ 7.1176e-01,  1.1995e+00,  9.1065e-01,  7.5163e-01, -3.8769e-02,\n",
      "          1.1397e+00,  4.6515e-01,  8.4317e-01, -6.1288e+00, -4.2530e+00],\n",
      "        [ 7.3432e-01,  1.5386e+00,  9.9586e-01,  7.0892e-01, -5.6228e-01,\n",
      "          1.4202e+00,  1.6015e-01,  1.1758e+00, -6.0154e+00, -4.1554e+00],\n",
      "        [ 7.7660e-01,  1.7473e+00,  7.0054e-01,  6.8564e-01, -6.1164e-01,\n",
      "          1.3301e+00,  6.5647e-02,  1.3404e+00, -5.9308e+00, -4.1131e+00],\n",
      "        [ 5.3239e-02,  1.1149e+00,  1.3580e+00,  6.3172e-01,  7.5773e-01,\n",
      "          1.0870e+00,  7.8390e-01,  7.5047e-01, -1.3524e+01, -7.6635e+00],\n",
      "        [ 5.8290e-01,  1.1284e+00,  8.1131e-01,  8.8387e-01,  8.9722e-02,\n",
      "          1.0795e+00,  5.0021e-01,  8.3123e-01, -6.1385e+00, -4.2546e+00],\n",
      "        [ 2.4759e-01,  1.4681e-01,  9.5455e-01,  1.0457e+00,  1.1910e+00,\n",
      "          7.4073e-01,  1.3000e+00,  8.1341e-02, -6.4918e+00, -4.4720e+00],\n",
      "        [ 3.8745e-01,  1.5128e+00,  1.1921e+00,  8.1002e-01, -5.7558e-01,\n",
      "          1.5112e+00,  1.4936e-01,  1.1076e+00, -5.9138e+00, -4.0338e+00],\n",
      "        [-5.3200e-01,  8.1923e-01, -7.2477e-03, -3.1948e-01,  6.5795e+00,\n",
      "         -7.2340e-01,  1.5298e+00,  5.3633e+00, -5.7405e+01, -2.9332e+01],\n",
      "        [ 1.3981e-01,  9.3731e-01,  7.4663e-01,  3.5426e-01,  2.1918e+00,\n",
      "          4.3546e-01,  1.2330e+00,  1.8603e+00, -2.3818e+01, -1.2667e+01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>) is logits\n",
      "****************logits************\n",
      "\n",
      "<class 'torch.Tensor'> is logits's type\n",
      "***************logits's type*************\n",
      "\n",
      "torch.Size([32, 10]) is logits's shape\n",
      "***************logits's shape*************\n",
      "\n",
      "tensor([1.0935, 1.1543, 1.1249, 1.5088, 0.9558, 1.1630, 1.0991, 1.5385, 1.8543,\n",
      "        1.9674, 1.1206, 1.2706, 2.0671, 1.2699, 1.1113, 1.2157, 1.3879, 1.2353,\n",
      "        1.1655, 1.5693, 0.9437, 1.3640, 1.1970, 1.1995, 1.5386, 1.7473, 1.3580,\n",
      "        1.1284, 1.3000, 1.5128, 6.5795, 2.1918], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>) is _\n",
      "***************_*************\n",
      "\n",
      "tensor([5, 2, 6, 1, 5, 2, 2, 1, 4, 4, 6, 5, 4, 2, 5, 2, 5, 1, 1, 1, 5, 2, 1, 1,\n",
      "        1, 1, 2, 1, 6, 1, 4, 4], device='cuda:0') is predict\n",
      "**************predict**************\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-65124ea35388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "# start = time.time() #시작 시간 저장\n",
    "# Train\n",
    "# writer = SummaryWriter(\"./runs/11.18_loss접근 후 backward+step\")\n",
    "for epoch in range(1):\n",
    "    \n",
    "#     if epoch == 0:\n",
    "#         start = time.time() #시작 시간 저장\n",
    "#     if epoch == 1:\n",
    "#         epoch_time_for_1 = time.time()-start\n",
    "#         timer = epoch_time_for_1 * num_epoch\n",
    "#         print(\"학습에 총 걸리는 시간 :\", timer)    \n",
    "    \n",
    "    \n",
    "\n",
    "    print(f\"====== { epoch+1} epoch of { num_epoch } ======\")\n",
    "    model.train()\n",
    "    lr_scheduler(optimizer, epoch)\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    total_cnt = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Train Phase\n",
    "    for step, batch in enumerate(test_loader):\n",
    "        #  input and target\n",
    "        batch[0], batch[1] = batch[0].to(device), batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        print(f\"{batch[1]} is batch[1]\\n******************batch[1]****************\\n\")\n",
    "        print(f\"{type(batch[1])} is batch[1]'s type\\n****************batch[1]'s type******************\\n\")\n",
    "        print(f\"{batch[1].shape} is batch[1].shape\\n*****************batch[1].shape*****************\\n\")\n",
    "        \n",
    "        logits = model(batch[0]) # 모델에 이미지 집어넣기\n",
    "        print(f\"{logits} is logits\\n****************logits************\\n\")\n",
    "        print(f\"{type(logits)} is logits's type\\n***************logits's type*************\\n\")\n",
    "        print(f\"{logits.shape} is logits's shape\\n***************logits's shape*************\\n\")\n",
    "        \n",
    "        loss = loss_fn(logits, batch[1]) # tensor(1.3~~~)이런식으로 나옴.\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        #_, predict = logits.max(1)\n",
    "        _, predict = torch.max(logits, dim=1)\n",
    "        print(f\"{_} is _\\n***************_*************\\n\")\n",
    "        print(f\"{predict} is predict\\n**************predict**************\\n\")\n",
    "        \n",
    "        total_cnt += batch[1].size(0)\n",
    "        correct +=  predict.eq(batch[1]).sum().item()\n",
    "        \n",
    "        if step % 1000 == 0 and step != 0:\n",
    "            print(f\"\\n====== { step } Step of { len(train_loader) } ======\")\n",
    "            print(f\"Train Acc : { correct / total_cnt }\")\n",
    "            print(f\"Train Loss : { loss.item() / batch[1].size(0) }\")\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "            \n",
    "    train_acc_visual = (correct / total_cnt) * 100\n",
    "    train_loss_visual = train_loss / batch[1].size(0)\n",
    "    writer.add_scalar('acc/train', train_acc_visual, epoch)\n",
    "    writer.add_scalar('loss/train', train_loss_visual, epoch)            \n",
    "            \n",
    "\n",
    "    correct = 0\n",
    "    total_cnt = 0\n",
    "    \n",
    "# Test Phase\n",
    "#     with torch.no_grad():\n",
    "#         model.eval()\n",
    "#         for step, batch in enumerate(test_loader):\n",
    "#             # input and target\n",
    "#             batch[0], batch[1] = batch[0].to(device), batch[1].to(device)\n",
    "#             total_cnt += batch[1].size(0)\n",
    "#             logits = model(batch[0])\n",
    "#             valid_loss += loss_fn(logits, batch[1])\n",
    "#             _, predict = logits.max(1)\n",
    "#             correct += predict.eq(batch[1]).sum().item()\n",
    "#         valid_acc = correct / total_cnt\n",
    "#         print(f\"\\nValid Acc : { valid_acc }\")    \n",
    "#         print(f\"Valid Loss : { valid_loss / total_cnt }\")\n",
    "        \n",
    "#         valid_acc_visual = valid_acc * 100\n",
    "#         valid_loss_visual = valid_loss / total_cnt\n",
    "#         writer.add_scalar('acc/valid', valid_acc_visual, epoch)\n",
    "#         writer.add_scalar('loss/valid', valid_loss_visual, epoch)\n",
    "        \n",
    "        \n",
    "\n",
    "#         if(valid_acc > best_acc):\n",
    "#             best_acc = valid_acc\n",
    "#             # torch.save(model, model_name)\n",
    "#             # print(\"Model Saved!\")\n",
    "#             torch.save(model.state_dict(), model_name)\n",
    "#             print('Model Saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
